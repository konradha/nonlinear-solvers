Many modules are hidden in this stack. Use "module --show_hidden spider SOFTWARE" if you are not able to find the required software
I0227 18:02:19.736000 22699002779456 torch/_dynamo/logging.py:55] [0/0] Step 1: torchdynamo start tracing neumann_bc /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:18
V0227 18:02:19.741000 22699002779456 torch/fx/experimental/symbolic_shapes.py:1980] [0/0] create_env
V0227 18:02:19.773000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:18 in neumann_bc (neumann_bc)
V0227 18:02:19.773000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]     def neumann_bc(u: torch.Tensor, nx: int, ny: int) -> torch.Tensor:
V0227 18:02:31.658000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE RESUME 0 []
V0227 18:02:31.663000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc (neumann_bc)
V0227 18:02:31.663000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         assert len(u.shape) == 2
V0227 18:02:31.663000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_GLOBAL len []
V0227 18:02:31.665000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [NullVariable(), BuiltinVariable()]
V0227 18:02:31.665000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_ATTR shape [NullVariable(), BuiltinVariable(), LazyVariableTracker()]
V0227 18:02:31.666000 22699002779456 torch/_dynamo/output_graph.py:1959] [0/0] create_graph_input L_u_ L['u']
V0227 18:02:31.690000 22699002779456 torch/_dynamo/variables/builder.py:1873] [0/0] wrap_to_fake L['u'] (300, 300) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.DUCK: 1>, <DimDynamic.DUCK: 1>], constraint_sizes=[None, None], view_base_context=None, tensor_source=LocalSource(local_name='u', cell_or_freevar=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>
I0227 18:02:31.972000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2724] [0/0] create_symbol s0 = 300 for L['u'].size()[0] [2, 9223372036854775806] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc (_dynamo/variables/builder.py:1881 in <lambda>)
V0227 18:02:31.972000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2735] [0/0] create_symbol s0 duck sized L['u'].size()[1]
V0227 18:02:31.974000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval True == True [statically known]
V0227 18:02:31.975000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval False == False [statically known]
V0227 18:02:31.982000 22699002779456 torch/_dynamo/output_graph.py:658] [0/0] bind_symint s0 L['u'].size()[0]
V0227 18:02:31.983000 22699002779456 torch/_dynamo/output_graph.py:1959] [0/0] create_graph_input s0 L['u'].size()[0]
V0227 18:02:31.983000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call size from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc (neumann_bc)
V0227 18:02:31.983000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     assert len(u.shape) == 2
V0227 18:02:31.983000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                ^^^^^^^
V0227 18:02:31.984000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE PRECALL 1 [NullVariable(), BuiltinVariable(), SizeVariable()]
V0227 18:02:31.984000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE CALL 1 [NullVariable(), BuiltinVariable(), SizeVariable()]
V0227 18:02:31.985000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 2 [ConstantVariable()]
V0227 18:02:31.985000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE COMPARE_OP == [ConstantVariable(), ConstantVariable()]
V0227 18:02:31.985000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE POP_JUMP_FORWARD_IF_TRUE 54 [ConstantVariable()]
V0227 18:02:31.985000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (neumann_bc)
V0227 18:02:31.985000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:02:31.985000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:02:31.985000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker()]
V0227 18:02:31.985000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), ConstantVariable()]
V0227 18:02:31.985000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:02:31.985000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker()]
V0227 18:02:31.985000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker(), ConstantVariable()]
I0227 18:02:31.986000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2724] [0/0] create_symbol s1 = 300 for L['ny'] [-9223372036854775808, 9223372036854775807] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (_dynamo/variables/builder.py:1241 in wrap_unspecialized_primitive)
V0227 18:02:31.986000 22699002779456 torch/_dynamo/output_graph.py:1959] [0/0] create_graph_input L_ny_ L['ny']
V0227 18:02:31.986000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call sub from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (neumann_bc)
V0227 18:02:31.986000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:02:31.986000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                              ~~^^
V0227 18:02:31.987000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), SymNodeVariable()]
V0227 18:02:31.987000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [LazyVariableTracker(), ConstantVariable(), SliceVariable()]
V0227 18:02:31.987000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_SUBSCR None [LazyVariableTracker(), TupleVariable()]
V0227 18:02:31.988000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call getitem_2 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (neumann_bc)
V0227 18:02:31.988000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:02:31.988000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                       ~^^^^^^^^^^^
V0227 18:02:31.991000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 > 1 == True [statically known]
V0227 18:02:31.992000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval False == False [statically known]
V0227 18:02:31.993000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 <= 1 == False [statically known]
I0227 18:02:32.020000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s1 - 1 >= 0 [guard added] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (_decomp/decompositions.py:746 in slice_forward)
I0227 18:02:32.027000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s1 - 1 >= 1 [guard added] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (_decomp/decompositions.py:754 in slice_forward)
I0227 18:02:32.040000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s1 - 1 <= s0 [guard added] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (_decomp/decompositions.py:756 in slice_forward)
V0227 18:02:32.041000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [TensorVariable()]
V0227 18:02:32.041000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 0 [TensorVariable(), LazyVariableTracker()]
V0227 18:02:32.041000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:32.041000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:02:32.041000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker()]
V0227 18:02:32.042000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:32.042000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call sub_1 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (neumann_bc)
V0227 18:02:32.042000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:02:32.042000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]            ~~^^
V0227 18:02:32.042000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), SymNodeVariable()]
V0227 18:02:32.042000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), SliceVariable()]
V0227 18:02:32.042000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE STORE_SUBSCR None [TensorVariable(), LazyVariableTracker(), TupleVariable()]
V0227 18:02:32.043000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call setitem from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (neumann_bc)
V0227 18:02:32.043000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:02:32.043000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     ~^^^^^^^^^^^
V0227 18:02:32.043000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:02:32.043000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:02:32.043000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:02:32.043000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST nx [LazyVariableTracker()]
V0227 18:02:32.043000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 2 [LazyVariableTracker(), LazyVariableTracker()]
V0227 18:02:32.043000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [LazyVariableTracker(), LazyVariableTracker(), ConstantVariable()]
I0227 18:02:32.044000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2724] [0/0] create_symbol s2 = 300 for L['nx'] [-9223372036854775808, 9223372036854775807] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (_dynamo/variables/builder.py:1241 in wrap_unspecialized_primitive)
V0227 18:02:32.044000 22699002779456 torch/_dynamo/output_graph.py:1959] [0/0] create_graph_input L_nx_ L['nx']
V0227 18:02:32.044000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call sub_2 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:02:32.044000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:02:32.044000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                         ~~^^
V0227 18:02:32.045000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), SymNodeVariable()]
V0227 18:02:32.045000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [LazyVariableTracker(), SymNodeVariable(), ConstantVariable()]
V0227 18:02:32.045000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), SymNodeVariable(), ConstantVariable(), LazyVariableTracker()]
V0227 18:02:32.045000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [LazyVariableTracker(), SymNodeVariable(), ConstantVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:32.045000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call sub_3 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:02:32.045000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:02:32.045000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                                 ~~^^
V0227 18:02:32.045000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [LazyVariableTracker(), SymNodeVariable(), ConstantVariable(), SymNodeVariable()]
V0227 18:02:32.046000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [LazyVariableTracker(), SymNodeVariable(), SliceVariable()]
V0227 18:02:32.046000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_SUBSCR None [LazyVariableTracker(), TupleVariable()]
V0227 18:02:32.046000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call getitem_3 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:02:32.046000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:02:32.046000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                       ~^^^^^^^^^^^^^^
I0227 18:02:32.050000 22699002779456 torch/fx/experimental/symbolic_shapes.py:3809] [0/0] set_replacement s2 = 300 (solve_backed) ValueRanges(lower=300, upper=300, is_bool=False)
I0227 18:02:32.051000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval Eq(s2 - 2, 298) [guard added] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (_dynamo/utils.py:1764 in run_node)
I0227 18:02:32.057000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s0 > 298 [guard added] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (_dynamo/utils.py:1764 in run_node)
V0227 18:02:32.059000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 <= 298 == False [statically known]
V0227 18:02:32.061000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [TensorVariable()]
V0227 18:02:32.061000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST nx [TensorVariable(), LazyVariableTracker()]
V0227 18:02:32.061000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), LazyVariableTracker()]
V0227 18:02:32.061000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [TensorVariable(), LazyVariableTracker(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:32.061000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call sub_4 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:02:32.061000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:02:32.061000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]       ~~^^
I0227 18:02:32.063000 22699002779456 torch/fx/experimental/symbolic_shapes.py:3809] [0/0] set_replacement s2 = 300 (find) ValueRanges(lower=300, upper=300, is_bool=False)
V0227 18:02:32.063000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), SymNodeVariable()]
V0227 18:02:32.063000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [TensorVariable(), LazyVariableTracker(), SymNodeVariable(), ConstantVariable()]
V0227 18:02:32.064000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), SymNodeVariable(), ConstantVariable(), LazyVariableTracker()]
V0227 18:02:32.064000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [TensorVariable(), LazyVariableTracker(), SymNodeVariable(), ConstantVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:32.064000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call sub_5 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:02:32.064000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:02:32.064000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]               ~~^^
V0227 18:02:32.064000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [TensorVariable(), LazyVariableTracker(), SymNodeVariable(), ConstantVariable(), SymNodeVariable()]
V0227 18:02:32.064000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [TensorVariable(), LazyVariableTracker(), SymNodeVariable(), SliceVariable()]
V0227 18:02:32.064000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE STORE_SUBSCR None [TensorVariable(), LazyVariableTracker(), TupleVariable()]
V0227 18:02:32.065000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call setitem_1 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:02:32.065000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:02:32.065000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     ~^^^^^^^^^^^^^^
V0227 18:02:32.065000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc (neumann_bc)
V0227 18:02:32.065000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         u[:, 0]    = u[:, 1]
V0227 18:02:32.065000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:02:32.065000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [LazyVariableTracker()]
V0227 18:02:32.065000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [LazyVariableTracker(), ConstantVariable()]
V0227 18:02:32.065000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:02:32.065000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), SliceVariable()]
V0227 18:02:32.065000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [LazyVariableTracker(), SliceVariable(), ConstantVariable()]
V0227 18:02:32.066000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_SUBSCR None [LazyVariableTracker(), TupleVariable()]
V0227 18:02:32.066000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call getitem_4 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc (neumann_bc)
V0227 18:02:32.066000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, 0]    = u[:, 1]
V0227 18:02:32.066000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                  ~^^^^^^
V0227 18:02:32.071000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval Eq(s0, 9223372036854775807) == False [statically known]
V0227 18:02:32.073000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 < 9223372036854775807 == True [statically known]
V0227 18:02:32.075000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [TensorVariable()]
V0227 18:02:32.075000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [TensorVariable(), LazyVariableTracker()]
V0227 18:02:32.075000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [TensorVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:32.075000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:02:32.075000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 0 [TensorVariable(), LazyVariableTracker(), SliceVariable()]
V0227 18:02:32.075000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [TensorVariable(), LazyVariableTracker(), SliceVariable(), ConstantVariable()]
V0227 18:02:32.075000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE STORE_SUBSCR None [TensorVariable(), LazyVariableTracker(), TupleVariable()]
V0227 18:02:32.075000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call setitem_2 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc (neumann_bc)
V0227 18:02:32.075000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, 0]    = u[:, 1]
V0227 18:02:32.075000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     ~^^^^^^
V0227 18:02:32.076000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (neumann_bc)
V0227 18:02:32.076000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         u[:, ny-1] = u[:, ny-2]
V0227 18:02:32.076000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:02:32.076000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [LazyVariableTracker()]
V0227 18:02:32.076000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [LazyVariableTracker(), ConstantVariable()]
V0227 18:02:32.076000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:02:32.076000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [LazyVariableTracker(), SliceVariable()]
V0227 18:02:32.076000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 2 [LazyVariableTracker(), SliceVariable(), LazyVariableTracker()]
V0227 18:02:32.076000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [LazyVariableTracker(), SliceVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:32.076000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call sub_6 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (neumann_bc)
V0227 18:02:32.076000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, ny-1] = u[:, ny-2]
V0227 18:02:32.076000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                       ~~^^
V0227 18:02:32.077000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [LazyVariableTracker(), SliceVariable(), SymNodeVariable()]
V0227 18:02:32.077000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_SUBSCR None [LazyVariableTracker(), TupleVariable()]
V0227 18:02:32.077000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call getitem_5 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (neumann_bc)
V0227 18:02:32.077000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, ny-1] = u[:, ny-2]
V0227 18:02:32.077000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                  ~^^^^^^^^^
I0227 18:02:32.082000 22699002779456 torch/fx/experimental/symbolic_shapes.py:3809] [0/0] set_replacement s1 = 300 (solve_backed) ValueRanges(lower=300, upper=300, is_bool=False)
I0227 18:02:32.082000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval Eq(s1 - 2, 298) [guard added] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (_dynamo/utils.py:1764 in run_node)
V0227 18:02:32.083000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [TensorVariable()]
V0227 18:02:32.083000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [TensorVariable(), LazyVariableTracker()]
V0227 18:02:32.083000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [TensorVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:32.083000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:02:32.083000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [TensorVariable(), LazyVariableTracker(), SliceVariable()]
V0227 18:02:32.083000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), SliceVariable(), LazyVariableTracker()]
V0227 18:02:32.083000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [TensorVariable(), LazyVariableTracker(), SliceVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:32.083000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call sub_7 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (neumann_bc)
V0227 18:02:32.083000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, ny-1] = u[:, ny-2]
V0227 18:02:32.083000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]          ~~^^
I0227 18:02:32.085000 22699002779456 torch/fx/experimental/symbolic_shapes.py:3809] [0/0] set_replacement s1 = 300 (find) ValueRanges(lower=300, upper=300, is_bool=False)
V0227 18:02:32.086000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [TensorVariable(), LazyVariableTracker(), SliceVariable(), SymNodeVariable()]
V0227 18:02:32.086000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE STORE_SUBSCR None [TensorVariable(), LazyVariableTracker(), TupleVariable()]
V0227 18:02:32.086000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call setitem_3 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (neumann_bc)
V0227 18:02:32.086000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, ny-1] = u[:, ny-2]
V0227 18:02:32.086000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     ~^^^^^^^^^
V0227 18:02:32.086000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:27 in neumann_bc (neumann_bc)
V0227 18:02:32.086000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         return u
V0227 18:02:32.086000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:02:32.086000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE RETURN_VALUE None [LazyVariableTracker()]
I0227 18:02:32.087000 22699002779456 torch/_dynamo/logging.py:55] [0/0] Step 1: torchdynamo done tracing neumann_bc (RETURN_VALUE)
V0227 18:02:32.087000 22699002779456 torch/_dynamo/symbolic_convert.py:2267] [0/0] RETURN_VALUE triggered compile
V0227 18:02:32.087000 22699002779456 torch/_dynamo/output_graph.py:871] [0/0] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py, line 27 in neumann_bc>], graph_break=False)
I0227 18:02:32.089000 22699002779456 torch/fx/experimental/symbolic_shapes.py:3809] [0/0] set_replacement s2 = 300 (find) ValueRanges(lower=300, upper=300, is_bool=False)
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code] TRACED GRAPH
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]  ===== __compiled_fn_0 =====
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]  /cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]     def forward(self, s0 : torch.SymInt, L_u_ : torch.Tensor, L_ny_ : torch.SymInt, L_nx_ : torch.SymInt):
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_ = L_u_
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_ny_ = L_ny_
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_nx_ = L_nx_
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc, code: assert len(u.shape) == 2
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         size = l_u_.size()
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc, code: u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         sub = l_ny_ - 1
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         getitem_2 = l_u_[(1, slice(1, sub, None))];  sub = None
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         sub_1 = l_ny_ - 1
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_[(0, slice(1, sub_1, None))] = getitem_2;  setitem = l_u_;  sub_1 = getitem_2 = None
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc, code: u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         sub_2 = l_nx_ - 2
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         sub_3 = l_ny_ - 1
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         getitem_3 = l_u_[(sub_2, slice(1, sub_3, None))];  sub_2 = sub_3 = None
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         sub_4 = l_nx_ - 1;  l_nx_ = None
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         sub_5 = l_ny_ - 1
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_[(sub_4, slice(1, sub_5, None))] = getitem_3;  setitem_1 = l_u_;  sub_4 = sub_5 = getitem_3 = None
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc, code: u[:, 0]    = u[:, 1]
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         getitem_4 = l_u_[(slice(None, None, None), 1)]
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_[(slice(None, None, None), 0)] = getitem_4;  setitem_2 = l_u_;  getitem_4 = None
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc, code: u[:, ny-1] = u[:, ny-2]
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         sub_6 = l_ny_ - 2
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         getitem_5 = l_u_[(slice(None, None, None), sub_6)];  sub_6 = None
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         sub_7 = l_ny_ - 1;  l_ny_ = None
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_[(slice(None, None, None), sub_7)] = getitem_5;  setitem_3 = l_u_;  sub_7 = getitem_5 = None
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         return (l_u_,)
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:02:32.089000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code] 
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] TRACED GRAPH
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph]  __compiled_fn_0 /cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/fx/_lazy_graph_module.py opcode         name       target                       args                                                 kwargs
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] -------------  ---------  ---------------------------  ---------------------------------------------------  --------
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] placeholder    s0         s0                           ()                                                   {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] placeholder    l_u_       L_u_                         ()                                                   {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] placeholder    l_ny_      L_ny_                        ()                                                   {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] placeholder    l_nx_      L_nx_                        ()                                                   {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_method    size       size                         (l_u_,)                                              {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  sub        <built-in function sub>      (l_ny_, 1)                                           {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  getitem_2  <built-in function getitem>  (l_u_, (1, slice(1, sub, None)))                     {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  sub_1      <built-in function sub>      (l_ny_, 1)                                           {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  setitem    <built-in function setitem>  (l_u_, (0, slice(1, sub_1, None)), getitem_2)        {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  sub_2      <built-in function sub>      (l_nx_, 2)                                           {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  sub_3      <built-in function sub>      (l_ny_, 1)                                           {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  getitem_3  <built-in function getitem>  (l_u_, (sub_2, slice(1, sub_3, None)))               {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  sub_4      <built-in function sub>      (l_nx_, 1)                                           {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  sub_5      <built-in function sub>      (l_ny_, 1)                                           {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  setitem_1  <built-in function setitem>  (l_u_, (sub_4, slice(1, sub_5, None)), getitem_3)    {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  getitem_4  <built-in function getitem>  (l_u_, (slice(None, None, None), 1))                 {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  setitem_2  <built-in function setitem>  (l_u_, (slice(None, None, None), 0), getitem_4)      {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  sub_6      <built-in function sub>      (l_ny_, 2)                                           {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  getitem_5  <built-in function getitem>  (l_u_, (slice(None, None, None), sub_6))             {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  sub_7      <built-in function sub>      (l_ny_, 1)                                           {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  setitem_3  <built-in function setitem>  (l_u_, (slice(None, None, None), sub_7), getitem_5)  {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] output         output     output                       ((l_u_,),)                                           {}
V0227 18:02:32.092000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] 
V0227 18:02:32.224000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] TRACED GRAPH TENSOR SIZES
V0227 18:02:32.224000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] ===== __compiled_fn_0 =====
V0227 18:02:32.224000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] l_u_: (s0, s0)
V0227 18:02:32.224000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] l_u_ (concrete): (300, 300)
V0227 18:02:32.224000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_2: (298,)
V0227 18:02:32.224000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_2 (concrete): (298,)
V0227 18:02:32.224000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_3: (298,)
V0227 18:02:32.224000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_3 (concrete): (298,)
V0227 18:02:32.224000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_4: (s0,)
V0227 18:02:32.224000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_4 (concrete): (300,)
V0227 18:02:32.224000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_5: (s0,)
V0227 18:02:32.224000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_5 (concrete): (300,)
V0227 18:02:32.224000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] 
I0227 18:02:32.226000 22699002779456 torch/_dynamo/logging.py:55] [0/0] Step 2: calling compiler function inductor
V0227 18:02:32.344000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval True == True [statically known]
V0227 18:02:32.347000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 < 299 == False [statically known]
V0227 18:02:33.175000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4107] [0/0] eval 298 [trivial]
V0227 18:02:33.181000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4107] [0/0] eval 299 [trivial]
I0227 18:02:33.204000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s0 > 299 [guard added] (_functorch/_aot_autograd/traced_function_transforms.py:651 in run_node)
I0227 18:02:33.209000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s0 > 299 [guard added] (_meta_registrations.py:4980 in meta_select)
V0227 18:02:33.237000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval Ne(s0, 1) == True [statically known]
V0227 18:02:33.237000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval Eq(s0, 1) == False [statically known]
V0227 18:02:33.239000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 < 2 == False [statically known]
V0227 18:02:33.239000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval Eq(s0, 1) == False [statically known]
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs] TRACED GRAPH
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]  ===== Forward graph 0 =====
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]  /cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/fx/_lazy_graph_module.py class <lambda>(torch.nn.Module):
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]     def forward(self, arg0_1: "Sym(s0)", arg1_1: "f64[s0, s0]", arg2_1: "Sym(300)", arg3_1: "Sym(300)"):
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc, code: u[0, 1:ny-1]    = u[1, 1:ny-1]
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select: "f64[s0]" = torch.ops.aten.select.int(arg1_1, 0, 1)
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_1: "f64[298]" = torch.ops.aten.slice.Tensor(select, 0, 1, 299);  select = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_1: "f64[s0]" = torch.ops.aten.select.int(arg1_1, 0, 0)
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_2: "f64[298]" = torch.ops.aten.slice.Tensor(select_1, 0, 1, 299);  select_1 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         copy: "f64[298]" = torch.ops.aten.copy.default(slice_2, slice_1);  slice_2 = slice_1 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_2: "f64[s0]" = torch.ops.aten.select.int(arg1_1, 0, 0)
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_scatter: "f64[s0]" = torch.ops.aten.slice_scatter.default(select_2, copy, 0, 1, 299);  select_2 = copy = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_scatter: "f64[s0, s0]" = torch.ops.aten.select_scatter.default(arg1_1, slice_scatter, 0, 0);  slice_scatter = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc, code: u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_6: "f64[s0]" = torch.ops.aten.select.int(select_scatter, 0, 299)
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_6: "f64[298]" = torch.ops.aten.slice.Tensor(select_6, 0, 1, 299);  select_6 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_7: "f64[s0]" = torch.ops.aten.select.int(select_scatter, 0, 298)
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_7: "f64[298]" = torch.ops.aten.slice.Tensor(select_7, 0, 1, 299);  select_7 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         copy_1: "f64[298]" = torch.ops.aten.copy.default(slice_6, slice_7);  slice_6 = slice_7 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_8: "f64[s0]" = torch.ops.aten.select.int(select_scatter, 0, 299)
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_scatter_1: "f64[s0]" = torch.ops.aten.slice_scatter.default(select_8, copy_1, 0, 1, 299);  select_8 = copy_1 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_scatter_1: "f64[s0, s0]" = torch.ops.aten.select_scatter.default(select_scatter, slice_scatter_1, 0, 299);  select_scatter = slice_scatter_1 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc, code: u[:, 0]    = u[:, 1]
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_11: "f64[s0, s0]" = torch.ops.aten.slice.Tensor(select_scatter_1, 0, 0, 9223372036854775807)
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_12: "f64[s0]" = torch.ops.aten.select.int(slice_11, 1, 0);  slice_11 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_12: "f64[s0, s0]" = torch.ops.aten.slice.Tensor(select_scatter_1, 0, 0, 9223372036854775807)
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_13: "f64[s0]" = torch.ops.aten.select.int(slice_12, 1, 1);  slice_12 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         copy_2: "f64[s0]" = torch.ops.aten.copy.default(select_12, select_13);  select_12 = select_13 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_13: "f64[s0, s0]" = torch.ops.aten.slice.Tensor(select_scatter_1, 0, 0, 9223372036854775807)
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_scatter_2: "f64[s0, s0]" = torch.ops.aten.select_scatter.default(slice_13, copy_2, 1, 0);  slice_13 = copy_2 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_scatter_2: "f64[s0, s0]" = torch.ops.aten.slice_scatter.default(select_scatter_1, select_scatter_2, 0, 0, 9223372036854775807);  select_scatter_1 = select_scatter_2 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc, code: u[:, ny-1] = u[:, ny-2]
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_17: "f64[s0, s0]" = torch.ops.aten.slice.Tensor(slice_scatter_2, 0, 0, 9223372036854775807)
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_17: "f64[s0]" = torch.ops.aten.select.int(slice_17, 1, 299);  slice_17 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_18: "f64[s0, s0]" = torch.ops.aten.slice.Tensor(slice_scatter_2, 0, 0, 9223372036854775807)
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_18: "f64[s0]" = torch.ops.aten.select.int(slice_18, 1, 298);  slice_18 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         copy_3: "f64[s0]" = torch.ops.aten.copy.default(select_17, select_18);  select_17 = select_18 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_19: "f64[s0, s0]" = torch.ops.aten.slice.Tensor(slice_scatter_2, 0, 0, 9223372036854775807)
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_scatter_3: "f64[s0, s0]" = torch.ops.aten.select_scatter.default(slice_19, copy_3, 1, 299);  slice_19 = copy_3 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_scatter_3: "f64[s0, s0]" = torch.ops.aten.slice_scatter.default(slice_scatter_2, select_scatter_3, 0, 0, 9223372036854775807);  slice_scatter_2 = select_scatter_3 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         copy_: "f64[s0, s0]" = torch.ops.aten.copy_.default(arg1_1, slice_scatter_3);  arg1_1 = slice_scatter_3 = None
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         return (copy_,)
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         
I0227 18:02:33.460000 22699002779456 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs] 
I0227 18:02:34.149000 22699002779456 torch/_dynamo/logging.py:55] [0/0] Step 3: torchinductor compiling FORWARDS graph 0
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs] TRACED GRAPH
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]  ===== AFTER POST GRAD =====
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]  /cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/fx/_lazy_graph_module.py class <lambda>(torch.nn.Module):
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]     def forward(self, arg0_1: "Sym(s0)", arg1_1: "f64[s0, s0]", arg2_1: "Sym(300)", arg3_1: "Sym(300)"):
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc, code: u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_2: "f64[s0]" = torch.ops.aten.select.int(arg1_1, 0, 0)
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_1: "f64[s0]" = torch.ops.aten.select.int(arg1_1, 0, 0)
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         slice_2: "f64[298]" = torch.ops.aten.slice.Tensor(select_1, 0, 1, 299);  select_1 = None
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select: "f64[s0]" = torch.ops.aten.select.int(arg1_1, 0, 1)
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         slice_1: "f64[298]" = torch.ops.aten.slice.Tensor(select, 0, 1, 299);  select = None
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # No stacktrace found for following nodes
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_int: "f64[s0]" = torch.ops.aten.select.int(arg1_1, 0, 0)
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         slice_scatter_default: "f64[s0]" = torch.ops.aten.slice_scatter.default(select_int, slice_1, 0, 1, 299);  select_int = slice_1 = None
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_scatter_default: "f64[s0, s0]" = torch.ops.aten.select_scatter.default(arg1_1, slice_scatter_default, 0, 0);  slice_scatter_default = None
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc, code: u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_8: "f64[s0]" = torch.ops.aten.select.int(select_scatter_default, 0, 299)
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_6: "f64[s0]" = torch.ops.aten.select.int(select_scatter_default, 0, 299)
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         slice_6: "f64[298]" = torch.ops.aten.slice.Tensor(select_6, 0, 1, 299);  select_6 = None
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_7: "f64[s0]" = torch.ops.aten.select.int(select_scatter_default, 0, 298)
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         slice_7: "f64[298]" = torch.ops.aten.slice.Tensor(select_7, 0, 1, 299);  select_7 = None
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # No stacktrace found for following nodes
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_int_1: "f64[s0]" = torch.ops.aten.select.int(select_scatter_default, 0, 299)
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         slice_scatter_default_1: "f64[s0]" = torch.ops.aten.slice_scatter.default(select_int_1, slice_7, 0, 1, 299);  select_int_1 = slice_7 = None
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_scatter_default_1: "f64[s0, s0]" = torch.ops.aten.select_scatter.default(select_scatter_default, slice_scatter_default_1, 0, 299);  select_scatter_default = slice_scatter_default_1 = None
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc, code: u[:, 0]    = u[:, 1]
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_12: "f64[s0]" = torch.ops.aten.select.int(select_scatter_default_1, 1, 0)
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_13: "f64[s0]" = torch.ops.aten.select.int(select_scatter_default_1, 1, 1)
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # No stacktrace found for following nodes
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_scatter_default_2: "f64[s0, s0]" = torch.ops.aten.select_scatter.default(select_scatter_default_1, select_13, 1, 0);  select_scatter_default_1 = select_13 = None
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc, code: u[:, ny-1] = u[:, ny-2]
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_17: "f64[s0]" = torch.ops.aten.select.int(select_scatter_default_2, 1, 299)
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_18: "f64[s0]" = torch.ops.aten.select.int(select_scatter_default_2, 1, 298)
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # No stacktrace found for following nodes
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_scatter_default_3: "f64[s0, s0]" = torch.ops.aten.select_scatter.default(select_scatter_default_2, select_18, 1, 299);  select_scatter_default_2 = select_18 = None
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc, code: u[:, ny-1] = u[:, ny-2]
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         copy_: "f64[s0, s0]" = torch.ops.aten.copy_.default(arg1_1, select_scatter_default_3);  arg1_1 = select_scatter_default_3 = None
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         return (copy_,)
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:02:34.466000 22699002779456 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs] 
V0227 18:02:34.495000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %arg0_1 : [num_users=0] = placeholder[target=arg0_1] 
V0227 18:02:34.495000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %arg1_1 : [num_users=6] = placeholder[target=arg1_1] 
V0227 18:02:34.497000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %arg2_1 : [num_users=0] = placeholder[target=arg2_1] 
V0227 18:02:34.498000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %arg3_1 : [num_users=0] = placeholder[target=arg3_1] 
V0227 18:02:34.498000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %select_2 : [num_users=0] = call_function[target=torch.ops.aten.select.int](args = (%arg1_1, 0, 0), kwargs = {}) 
V0227 18:02:34.498000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x14a441256200>
V0227 18:02:34.499000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval False == False [statically known]
V0227 18:02:34.500000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval True == True [statically known]
V0227 18:02:34.502000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %select_1 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%arg1_1, 0, 0), kwargs = {}) 
V0227 18:02:34.502000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x14a441256200>
V0227 18:02:34.504000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %slice_2 : [num_users=0] = call_function[target=torch.ops.aten.slice.Tensor](args = (%select_1, 0, 1, 299), kwargs = {}) 
V0227 18:02:34.504000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function slice_ at 0x14a4412554e0>
V0227 18:02:34.508000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval 299 < s0 + 1 == True [statically known]
V0227 18:02:34.510000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %select : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%arg1_1, 0, 1), kwargs = {}) 
V0227 18:02:34.510000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x14a441256200>
V0227 18:02:34.513000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval 2 < s0 + 1 == True [statically known]
V0227 18:02:34.514000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%select, 0, 1, 299), kwargs = {}) 
V0227 18:02:34.514000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function slice_ at 0x14a4412554e0>
V0227 18:02:34.515000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %select_int : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%arg1_1, 0, 0), kwargs = {}) 
V0227 18:02:34.515000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x14a441256200>
V0227 18:02:34.516000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %slice_scatter_default : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%select_int, %slice_1, 0, 1, 299), kwargs = {}) 
V0227 18:02:34.516000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function slice_scatter at 0x14a4412d8e00>
V0227 18:02:34.521000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %select_scatter_default : [num_users=5] = call_function[target=torch.ops.aten.select_scatter.default](args = (%arg1_1, %slice_scatter_default, 0, 0), kwargs = {}) 
V0227 18:02:34.521000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function select_scatter at 0x14a4412d8cc0>
V0227 18:02:34.527000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %select_8 : [num_users=0] = call_function[target=torch.ops.aten.select.int](args = (%select_scatter_default, 0, 299), kwargs = {}) 
V0227 18:02:34.527000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x14a441256200>
I0227 18:02:34.583000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval 300 < s0 + 1 [guard added] (_inductor/ir.py:2320 in clamp)
V0227 18:02:34.586000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %select_6 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%select_scatter_default, 0, 299), kwargs = {}) 
V0227 18:02:34.587000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x14a441256200>
V0227 18:02:34.590000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %slice_6 : [num_users=0] = call_function[target=torch.ops.aten.slice.Tensor](args = (%select_6, 0, 1, 299), kwargs = {}) 
V0227 18:02:34.590000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function slice_ at 0x14a4412554e0>
V0227 18:02:34.593000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %select_7 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%select_scatter_default, 0, 298), kwargs = {}) 
V0227 18:02:34.593000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x14a441256200>
V0227 18:02:34.598000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval 298 < s0 + 1 == True [statically known]
V0227 18:02:34.600000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %slice_7 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%select_7, 0, 1, 299), kwargs = {}) 
V0227 18:02:34.600000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function slice_ at 0x14a4412554e0>
V0227 18:02:34.602000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %select_int_1 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%select_scatter_default, 0, 299), kwargs = {}) 
V0227 18:02:34.602000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x14a441256200>
V0227 18:02:34.604000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %slice_scatter_default_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%select_int_1, %slice_7, 0, 1, 299), kwargs = {}) 
V0227 18:02:34.604000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function slice_scatter at 0x14a4412d8e00>
V0227 18:02:34.608000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %select_scatter_default_1 : [num_users=3] = call_function[target=torch.ops.aten.select_scatter.default](args = (%select_scatter_default, %slice_scatter_default_1, 0, 299), kwargs = {}) 
V0227 18:02:34.608000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function select_scatter at 0x14a4412d8cc0>
I0227 18:02:34.650000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval 299 < s0 [guard added] (_inductor/lowering.py:2519 in select_scatter)
V0227 18:02:34.664000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %select_12 : [num_users=0] = call_function[target=torch.ops.aten.select.int](args = (%select_scatter_default_1, 1, 0), kwargs = {}) 
V0227 18:02:34.664000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x14a441256200>
V0227 18:02:34.671000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %select_13 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%select_scatter_default_1, 1, 1), kwargs = {}) 
V0227 18:02:34.671000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x14a441256200>
V0227 18:02:34.673000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %select_scatter_default_2 : [num_users=3] = call_function[target=torch.ops.aten.select_scatter.default](args = (%select_scatter_default_1, %select_13, 1, 0), kwargs = {}) 
V0227 18:02:34.673000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function select_scatter at 0x14a4412d8cc0>
V0227 18:02:34.677000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %select_17 : [num_users=0] = call_function[target=torch.ops.aten.select.int](args = (%select_scatter_default_2, 1, 299), kwargs = {}) 
V0227 18:02:34.678000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x14a441256200>
V0227 18:02:34.679000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %select_18 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%select_scatter_default_2, 1, 298), kwargs = {}) 
V0227 18:02:34.679000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x14a441256200>
V0227 18:02:34.681000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %select_scatter_default_3 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%select_scatter_default_2, %select_18, 1, 299), kwargs = {}) 
V0227 18:02:34.681000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function select_scatter at 0x14a4412d8cc0>
V0227 18:02:34.684000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering %copy_ : [num_users=1] = call_function[target=torch.ops.aten.copy_.default](args = (%arg1_1, %select_scatter_default_3), kwargs = {}) 
V0227 18:02:34.684000 22699002779456 torch/_inductor/graph.py:815] [0/0]   via <function copy_ at 0x14a4412fb1a0>
V0227 18:02:34.693000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0**2 < 2 == False [statically known]
V0227 18:02:34.694000 22699002779456 torch/_inductor/graph.py:925] [0/0] lowering return (copy_,) 
V0227 18:02:34.699000 22699002779456 torch/_inductor/graph.py:904] [0/0] Force channels last inputs for 0 conv for the current graph with id 0
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0] scheduling ComputedBuffer(name='buf0', layout=FixedLayout('cuda', torch.float64, size=[s0, s0], stride=[s0, 1]), data=Pointwise(
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   'cuda',
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   torch.float64,
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   def inner_fn(index):
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       i0, i1 = index
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp0 = ops.index_expr(i0, torch.int32)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp1 = ops.index_expr(299, torch.int32)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp2 = tmp0 == tmp1
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp3 = ops.index_expr(i1, torch.int64)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp4 = ops.index_expr(1, torch.int64)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp5 = tmp3 >= tmp4
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp6 = ops.index_expr(299, torch.int64)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp7 = tmp3 < tmp6
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp8 = tmp5 & tmp7
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp9 = ops.index_expr(298, torch.int32)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp10 = ops.index_expr(0, torch.int32)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp11 = tmp9 == tmp10
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp12 = ops.index_expr(i1, torch.int64)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp13 = ops.index_expr(1, torch.int64)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp14 = tmp12 >= tmp13
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp15 = ops.index_expr(299, torch.int64)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp16 = tmp12 < tmp15
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp17 = tmp14 & tmp16
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp18 = ops.load(arg1_1, i1 + s0)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp19 = ops.masked(tmp17, tmp18, 0.0)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp20 = ops.load(arg1_1, i1)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp21 = ops.where(tmp17, tmp19, tmp20)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp22 = ops.load(arg1_1, i1 + 298 * s0)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp23 = ops.where(tmp11, tmp21, tmp22)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp24 = ops.masked(tmp8, tmp23, 0.0)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp25 = ops.index_expr(299, torch.int32)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp26 = ops.index_expr(0, torch.int32)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp27 = tmp25 == tmp26
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp28 = ops.index_expr(i1, torch.int64)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp29 = ops.index_expr(1, torch.int64)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp30 = tmp28 >= tmp29
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp31 = ops.index_expr(299, torch.int64)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp32 = tmp28 < tmp31
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp33 = tmp30 & tmp32
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp34 = ops.load(arg1_1, i1 + s0)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp35 = ops.masked(tmp33, tmp34, 0.0)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp36 = ops.load(arg1_1, i1)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp37 = ops.where(tmp33, tmp35, tmp36)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp38 = ops.load(arg1_1, i1 + 299 * s0)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp39 = ops.where(tmp27, tmp37, tmp38)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp40 = ops.where(tmp8, tmp24, tmp39)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp41 = ops.index_expr(i0, torch.int32)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp42 = ops.index_expr(0, torch.int32)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp43 = tmp41 == tmp42
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp44 = ops.index_expr(i1, torch.int64)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp45 = ops.index_expr(1, torch.int64)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp46 = tmp44 >= tmp45
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp47 = ops.index_expr(299, torch.int64)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp48 = tmp44 < tmp47
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp49 = tmp46 & tmp48
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp50 = ops.load(arg1_1, i1 + s0)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp51 = ops.masked(tmp49, tmp50, 0.0)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp52 = ops.load(arg1_1, i1)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp53 = ops.where(tmp49, tmp51, tmp52)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp54 = ops.load(arg1_1, i1 + i0 * s0)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp55 = ops.where(tmp43, tmp53, tmp54)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp56 = ops.where(tmp2, tmp40, tmp55)
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       return tmp56
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   ,
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   ranges=[s0, s0],
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   origin_node=select_scatter_default_1,
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   origins={slice_scatter_default, select_scatter_default_1, sli...
V0227 18:02:34.825000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0] ))
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0] scheduling ComputedBuffer(name='buf1', layout=FixedLayout('cuda', torch.float64, size=[s0], stride=[1]), data=Pointwise(
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   'cuda',
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   torch.float64,
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   def inner_fn(index):
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       i0 = index
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp0 = ops.index_expr(i0, torch.int64)
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp1 = ops.index_expr(1, torch.int64)
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp2 = tmp0 >= tmp1
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp3 = ops.index_expr(299, torch.int64)
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp4 = tmp0 < tmp3
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp5 = tmp2 & tmp4
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp6 = ops.load(arg1_1, i0 + s0)
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp7 = ops.masked(tmp5, tmp6, 0.0)
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp8 = ops.load(arg1_1, i0)
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp9 = ops.where(tmp5, tmp7, tmp8)
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       return tmp9
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   ,
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   ranges=[s0],
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   origin_node=slice_scatter_default,
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   origins={slice_scatter_default}
V0227 18:02:34.829000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0] ))
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0] scheduling ComputedBuffer(name='buf2', layout=FixedLayout('cuda', torch.float64, size=[s0, s0], stride=[s0, 1]), data=Pointwise(
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   'cuda',
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   torch.float64,
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   def inner_fn(index):
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       i0, i1 = index
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp0 = ops.index_expr(i0, torch.int32)
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp1 = ops.index_expr(0, torch.int32)
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp2 = tmp0 == tmp1
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp3 = ops.index_expr(i1, torch.int64)
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp4 = ops.index_expr(1, torch.int64)
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp5 = tmp3 >= tmp4
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp6 = ops.index_expr(299, torch.int64)
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp7 = tmp3 < tmp6
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp8 = tmp5 & tmp7
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp9 = ops.load(arg1_1, i1 + s0)
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp10 = ops.masked(tmp8, tmp9, 0.0)
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp11 = ops.load(arg1_1, i1)
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp12 = ops.where(tmp8, tmp10, tmp11)
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp13 = ops.load(arg1_1, i1 + i0 * s0)
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp14 = ops.where(tmp2, tmp12, tmp13)
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       return tmp14
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   ,
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   ranges=[s0, s0],
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   origin_node=select_scatter_default,
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   origins={select_scatter_default, slice_scatter_default}
V0227 18:02:34.830000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0] ))
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0] scheduling ComputedBuffer(name='buf3', layout=FixedLayout('cuda', torch.float64, size=[s0], stride=[1]), data=Pointwise(
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   'cuda',
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   torch.float64,
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   def inner_fn(index):
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       i0 = index
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp0 = ops.index_expr(i0, torch.int64)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp1 = ops.index_expr(1, torch.int64)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp2 = tmp0 >= tmp1
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp3 = ops.index_expr(299, torch.int64)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp4 = tmp0 < tmp3
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp5 = tmp2 & tmp4
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp6 = ops.index_expr(298, torch.int32)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp7 = ops.index_expr(0, torch.int32)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp8 = tmp6 == tmp7
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp9 = ops.index_expr(i0, torch.int64)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp10 = ops.index_expr(1, torch.int64)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp11 = tmp9 >= tmp10
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp12 = ops.index_expr(299, torch.int64)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp13 = tmp9 < tmp12
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp14 = tmp11 & tmp13
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp15 = ops.load(arg1_1, i0 + s0)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp16 = ops.masked(tmp14, tmp15, 0.0)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp17 = ops.load(arg1_1, i0)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp18 = ops.where(tmp14, tmp16, tmp17)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp19 = ops.load(arg1_1, i0 + 298 * s0)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp20 = ops.where(tmp8, tmp18, tmp19)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp21 = ops.masked(tmp5, tmp20, 0.0)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp22 = ops.index_expr(299, torch.int32)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp23 = ops.index_expr(0, torch.int32)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp24 = tmp22 == tmp23
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp25 = ops.index_expr(i0, torch.int64)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp26 = ops.index_expr(1, torch.int64)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp27 = tmp25 >= tmp26
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp28 = ops.index_expr(299, torch.int64)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp29 = tmp25 < tmp28
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp30 = tmp27 & tmp29
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp31 = ops.load(arg1_1, i0 + s0)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp32 = ops.masked(tmp30, tmp31, 0.0)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp33 = ops.load(arg1_1, i0)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp34 = ops.where(tmp30, tmp32, tmp33)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp35 = ops.load(arg1_1, i0 + 299 * s0)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp36 = ops.where(tmp24, tmp34, tmp35)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp37 = ops.where(tmp5, tmp21, tmp36)
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       return tmp37
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   ,
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   ranges=[s0],
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   origin_node=slice_scatter_default_1,
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   origins={slice_scatter_default_1}
V0227 18:02:34.831000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0] ))
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0] scheduling ComputedBuffer(name='buf4', layout=FixedLayout('cuda', torch.float64, size=[s0, s0], stride=[s0, 1]), data=Pointwise(
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   'cuda',
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   torch.float64,
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   def inner_fn(index):
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       i0, i1 = index
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp0 = ops.index_expr(i1, torch.int32)
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp1 = ops.index_expr(299, torch.int32)
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp2 = tmp0 == tmp1
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp3 = ops.index_expr(298, torch.int32)
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp4 = ops.index_expr(0, torch.int32)
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp5 = tmp3 == tmp4
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp6 = ops.load(buf0, 1 + i0 * s0)
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp7 = ops.load(buf0, 298 + i0 * s0)
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp8 = ops.where(tmp5, tmp6, tmp7)
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp9 = ops.index_expr(i1, torch.int32)
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp10 = ops.index_expr(0, torch.int32)
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp11 = tmp9 == tmp10
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp12 = ops.load(buf0, 1 + i0 * s0)
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp13 = ops.load(buf0, i1 + i0 * s0)
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp14 = ops.where(tmp11, tmp12, tmp13)
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp15 = ops.where(tmp2, tmp8, tmp14)
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       return tmp15
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   ,
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   ranges=[s0, s0],
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   origin_node=select_scatter_default_3,
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   origins={select_scatter_default_3, select_scatter_default_2}
V0227 18:02:34.834000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0] ))
V0227 18:02:34.835000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0] scheduling ComputedBuffer(name='buf5', layout=MutationLayout('cuda', torch.float64, size=[s0, s0], stride=[s0, 1]), data=Pointwise(
V0227 18:02:34.835000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   'cuda',
V0227 18:02:34.835000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   torch.float64,
V0227 18:02:34.835000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   def inner_fn(index):
V0227 18:02:34.835000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       i0, i1 = index
V0227 18:02:34.835000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       tmp0 = ops.load(buf4, i1 + i0 * s0)
V0227 18:02:34.835000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]       return tmp0
V0227 18:02:34.835000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   ,
V0227 18:02:34.835000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   ranges=[s0, s0],
V0227 18:02:34.835000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   origin_node=None,
V0227 18:02:34.835000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0]   origins={select_scatter_default_3, copy_, select_scatter_defa...
V0227 18:02:34.835000 22699002779456 torch/_inductor/scheduler.py:1480] [0/0] ))
V0227 18:02:34.836000 22699002779456 torch/_inductor/scheduler.py:1539] [0/0] scheduling output arg1_1
V0227 18:02:34.836000 22699002779456 torch/_inductor/scheduler.py:1627] [0/0] removed dead node: buf1
V0227 18:02:34.836000 22699002779456 torch/_inductor/scheduler.py:1627] [0/0] removed dead node: buf2
V0227 18:02:34.836000 22699002779456 torch/_inductor/scheduler.py:1627] [0/0] removed dead node: buf3
I0227 18:02:34.845000 22699002779456 torch/_inductor/debug.py:469] [0/0] Writing debug ir to  /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/torch_compile_debug/run_2025_02_27_18_02_19_694268-pid_473718/torchinductor/model___9.0/ir_pre_fusion.txt
I0227 18:02:34.883000 22699002779456 torch/_inductor/debug.py:469] [0/0] Writing debug ir to  /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/torch_compile_debug/run_2025_02_27_18_02_19_694268-pid_473718/torchinductor/model___9.0/ir_post_fusion.txt
V0227 18:02:34.943000 22699002779456 torch/_inductor/scheduler.py:2298] [0/0] Generating code for node buf0 with estimated runtime 0.000000
I0227 18:02:35.063000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s0**2 < 2147483648 [guard added] (_inductor/codegen/triton.py:3300 in can_use_32bit_indexing)
I0227 18:02:35.080000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s0*(s0 - 1) + s0 < 2147483648 [guard added] (_inductor/codegen/triton.py:3302 in can_use_32bit_indexing)
V0227 18:02:36.195000 22699002779456 torch/_inductor/codegen/triton.py:3428] [0/0] Generating kernel code with kernel_name: triton_poi_fused_0
V0227 18:02:36.196000 22699002779456 torch/_inductor/scheduler.py:2298] [0/0] Generating code for node buf4_buf5 with estimated runtime 0.000000
V0227 18:02:36.209000 22699002779456 torch/_inductor/scheduler.py:2220] [0/0] remove_buffer('buf4')
V0227 18:02:36.210000 22699002779456 torch/_inductor/codegen/triton.py:3428] [0/0] Generating kernel code with kernel_name: triton_poi_fused_1
V0227 18:02:36.297000 22699002779456 torch/_inductor/triton_heuristics.py:170] [0/0] CachingAutotuner gets 2 configs for triton_
V0227 18:02:36.297000 22699002779456 torch/_inductor/triton_heuristics.py:176] [0/0] XBLOCK: 1024, num_warps: 4, num_ctas: 1, num_stages: 1, enable_warp_specialization: False, enable_persistent: False
V0227 18:02:36.297000 22699002779456 torch/_inductor/triton_heuristics.py:176] [0/0] XBLOCK: 512, num_warps: 8, num_ctas: 1, num_stages: 1, enable_warp_specialization: False, enable_persistent: False
V0227 18:02:39.274000 22699002779456 torch/_inductor/triton_heuristics.py:170] [0/0] CachingAutotuner gets 2 configs for triton_
V0227 18:02:39.274000 22699002779456 torch/_inductor/triton_heuristics.py:176] [0/0] XBLOCK: 1024, num_warps: 4, num_ctas: 1, num_stages: 1, enable_warp_specialization: False, enable_persistent: False
V0227 18:02:39.274000 22699002779456 torch/_inductor/triton_heuristics.py:176] [0/0] XBLOCK: 512, num_warps: 8, num_ctas: 1, num_stages: 1, enable_warp_specialization: False, enable_persistent: False
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1266] [0/0] Output code written to: /scratch/tmp.24755961.konradha/torchinductor_konradha/x5/cx5yjpum273nhwdrktkdsaw5jh7zzs66ixnigthl4j5xe5skn5iz.py
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] Output code: 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from ctypes import c_void_p, c_long
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] import torch
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] import math
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] import random
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] import os
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] import tempfile
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from math import inf, nan
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch import device, empty_strided
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.codecache import AsyncCompile
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] aten = torch.ops.aten
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] inductor_ops = torch.ops.inductor
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] reinterpret_tensor = torch.ops.inductor._reinterpret_tensor
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] async_compile = AsyncCompile()
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] # kernel path: /scratch/tmp.24755961.konradha/torchinductor_konradha/rq/crq3m3grnclfckvkksxrf2jg73hagwieolxo3rlgu2z2v663afl3.py
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] # Source Nodes: [], Original ATen: []
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] triton_poi_fused_0 = async_compile.triton('triton_', '''
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] import triton
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] import triton.language as tl
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor import triton_helpers, triton_heuristics
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.ir import ReductionHint, TileHint
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.triton_helpers import libdevice, math as tl_math
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.triton_heuristics import AutotuneHint
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.utils import instance_descriptor
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] @triton_heuristics.pointwise(
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     size_hints=[131072], 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     filename=__file__,
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     triton_meta={'signature': {0: '*fp64', 1: '*fp64', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]},
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_0', 'mutated_arg_names': [], 'no_x_dim': False, 'backend_hash': '3c9eac74f04023b38fe37317f0afe4f78f5f0ccf49418abd41d59a08f8a919b2'},
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     min_elem_per_thread=0
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] )
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] @triton.jit
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] def triton_(in_ptr0, out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     xmask = xindex < xnumel
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     x1 = (xindex // ks0)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     x0 = xindex % ks0
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     x2 = xindex
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp26 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp28 = tl.load(in_ptr0 + (x0 + (299*ks0)), xmask, eviction_policy='evict_last')
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp32 = tl.load(in_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp0 = x1
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp1 = tl.full([1], 299, tl.int32)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp2 = tmp0 == tmp1
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp3 = x0
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp4 = tl.full([1], 1, tl.int64)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp5 = tmp3 >= tmp4
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp6 = tl.full([1], 299, tl.int64)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp7 = tmp3 < tmp6
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp8 = tmp5 & tmp7
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp9 = tl.full([1], 298, tl.int32)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp10 = tl.full([1], 0, tl.int32)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp11 = tmp9 == tmp10
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp12 = tmp8 & tmp8
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp13 = tl.load(in_ptr0 + (ks0 + x0), tmp12 & xmask, eviction_policy='evict_last', other=0.0)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp14 = tl.full(tmp13.shape, 0.0, tmp13.dtype)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp15 = tl.where(tmp12, tmp13, tmp14)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp16 = tl.load(in_ptr0 + (x0), tmp8 & xmask, eviction_policy='evict_last', other=0.0)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp17 = tl.where(tmp8, tmp15, tmp16)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp18 = tl.load(in_ptr0 + (x0 + (298*ks0)), tmp8 & xmask, eviction_policy='evict_last', other=0.0)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp19 = tl.where(tmp11, tmp17, tmp18)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp20 = tl.full(tmp19.shape, 0.0, tmp19.dtype)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp21 = tl.where(tmp8, tmp19, tmp20)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp22 = tmp1 == tmp10
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp23 = tl.load(in_ptr0 + (ks0 + x0), tmp8 & xmask, eviction_policy='evict_last', other=0.0)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp24 = tl.full(tmp23.shape, 0.0, tmp23.dtype)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp25 = tl.where(tmp8, tmp23, tmp24)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp27 = tl.where(tmp8, tmp25, tmp26)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp29 = tl.where(tmp22, tmp27, tmp28)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp30 = tl.where(tmp8, tmp21, tmp29)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp31 = tmp0 == tmp10
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp33 = tl.where(tmp31, tmp27, tmp32)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp34 = tl.where(tmp2, tmp30, tmp33)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp34, xmask)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] ''', device_str='cuda')
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] import triton
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] import triton.language as tl
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.triton_heuristics import grid, split_scan_grid, start_graph, end_graph
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] # kernel path: /scratch/tmp.24755961.konradha/torchinductor_konradha/uv/cuvi747mgngom33pwxvrie4po5isymwvermlnz5tybblus7yhtl5.py
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] # Source Nodes: [], Original ATen: []
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] triton_poi_fused_1 = async_compile.triton('triton_', '''
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] import triton
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] import triton.language as tl
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor import triton_helpers, triton_heuristics
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.ir import ReductionHint, TileHint
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.triton_helpers import libdevice, math as tl_math
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.triton_heuristics import AutotuneHint
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.utils import instance_descriptor
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] @triton_heuristics.pointwise(
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     size_hints=[131072], 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     filename=__file__,
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     triton_meta={'signature': {0: '*fp64', 1: '*fp64', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]},
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_1', 'mutated_arg_names': ['out_ptr1'], 'no_x_dim': False, 'backend_hash': '3c9eac74f04023b38fe37317f0afe4f78f5f0ccf49418abd41d59a08f8a919b2'},
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     min_elem_per_thread=0
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] )
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] @triton.jit
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] def triton_(in_ptr0, out_ptr1, ks0, xnumel, XBLOCK : tl.constexpr):
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     xmask = xindex < xnumel
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     x0 = xindex % ks0
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     x1 = (xindex // ks0)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     x2 = xindex
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp6 = tl.load(in_ptr0 + (1 + (ks0*x1)), xmask, eviction_policy='evict_last')
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp7 = tl.load(in_ptr0 + (298 + (ks0*x1)), xmask, eviction_policy='evict_last')
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp10 = tl.load(in_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp0 = x0
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp1 = tl.full([1], 299, tl.int32)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp2 = tmp0 == tmp1
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp3 = tl.full([1], 298, tl.int32)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp4 = tl.full([1], 0, tl.int32)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp5 = tmp3 == tmp4
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp8 = tl.where(tmp5, tmp6, tmp7)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp9 = tmp0 == tmp4
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp11 = tl.where(tmp9, tmp6, tmp10)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp12 = tl.where(tmp2, tmp8, tmp11)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp12, xmask)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] ''', device_str='cuda')
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] async_compile.wait(globals())
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] del async_compile
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] def call(args):
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     arg0_1, arg1_1, arg2_1, arg3_1 = args
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     args.clear()
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     s0 = arg0_1
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     for kernel in globals().values():
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]         if isinstance(kernel, torch._inductor.triton_heuristics.CachingAutotuner):
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]             kernel.cuda_kernel_saved = False
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]         torch.cuda.set_device(0)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]         buf0 = empty_strided_cuda((s0, s0), (s0, 1), torch.float64)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]         # Source Nodes: [], Original ATen: []
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]         triton_poi_fused_0_xnumel = s0*s0
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]         triton_poi_fused_0.run(arg1_1, buf0, s0, triton_poi_fused_0_xnumel, grid=grid(triton_poi_fused_0_xnumel), stream=stream0)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]         torch.cuda.synchronize()
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]         # Source Nodes: [], Original ATen: []
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]         triton_poi_fused_1_xnumel = s0*s0
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]         triton_poi_fused_1.run(buf0, arg1_1, s0, triton_poi_fused_1_xnumel, grid=grid(triton_poi_fused_1_xnumel), stream=stream0)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]         del buf0
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]         torch.cuda.synchronize()
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     for kernel in globals().values():
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]         if isinstance(kernel, torch._inductor.triton_heuristics.CachingAutotuner):
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]             if not kernel.cuda_kernel_saved:
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]                 if len(kernel.launchers) == 0:
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]                     kernel.precompile()
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]                 kernel.save_cuda_kernel(
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]                     grid=(0, 0, 0),   # use dummy grid
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]                     stream="stream",  # use dummy stream
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]                     launcher=kernel.launchers[0],
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]                 )
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     return (arg1_1, )
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     from torch._inductor.utils import print_performance
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     arg0_1 = 300
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     arg1_1 = rand_strided((300, 300), (300, 1), device='cuda:0', dtype=torch.float64)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     arg2_1 = 300
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     arg3_1 = 300
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1])
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] if __name__ == "__main__":
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
I0227 18:02:39.411000 22699002779456 torch/_inductor/graph.py:1273] [0/0] [__output_code] Output code written to: /scratch/tmp.24755961.konradha/torchinductor_konradha/x5/cx5yjpum273nhwdrktkdsaw5jh7zzs66ixnigthl4j5xe5skn5iz.py
V0227 18:02:39.487000 22699002779456 torch/_inductor/compile_fx.py:442] [0/0] FX codegen and compilation took 5.338s
I0227 18:02:39.487000 22699002779456 torch/_dynamo/logging.py:55] [0/0] Step 3: torchinductor done compiling FORWARDS graph 0
W0227 18:02:39.488000 22699002779456 torch/_inductor/debug.py:413] [0/0] model___9 debug trace: /scratch/tmp.24755961.konradha/torchinductor_konradha/x5/cx5yjpum273nhwdrktkdsaw5jh7zzs66ixnigthl4j5xe5skn5iz.debug
I0227 18:02:39.494000 22699002779456 torch/_dynamo/logging.py:55] [0/0] Step 2: done compiler function inductor
I0227 18:02:39.510000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2806] [0/0] produce_guards
V0227 18:02:39.510000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].size()[0] s0 None
V0227 18:02:39.510000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].size()[1] s0 None
V0227 18:02:39.510000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].stride()[0] s0 None
V0227 18:02:39.510000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].stride()[1] 1 None
V0227 18:02:39.511000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].storage_offset() 0 None
V0227 18:02:39.511000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['ny'] 300 None
V0227 18:02:39.511000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['nx'] 300 None
V0227 18:02:39.511000 22699002779456 torch/fx/experimental/symbolic_shapes.py:3138] [0/0] Skipping guard L['u'].stride()[1] == 1
V0227 18:02:39.511000 22699002779456 torch/fx/experimental/symbolic_shapes.py:3138] [0/0] Skipping guard L['u'].storage_offset() == 0
V0227 18:02:39.527000 22699002779456 torch/_dynamo/guards.py:1076] [0/0] [__guards] GUARDS:
V0227 18:02:39.527000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] ___check_type_id(L['u'], 78718768)                            # assert len(u.shape) == 2  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc
V0227 18:02:39.564000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] hasattr(L['u'], '_dynamo_dynamic_indices') == False           # assert len(u.shape) == 2  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc
V0227 18:02:39.582000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] ___check_type_id(L['nx'], 22699011583200)                     # u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc
V0227 18:02:39.583000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] ___check_type_id(L['ny'], 22699011583200)                     # u[0, 1:ny-1]    = u[1, 1:ny-1]  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc
V0227 18:02:39.584000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:430 in init_ambient_guards
V0227 18:02:39.584000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] ___check_current_backend(22695932050960)                      # _dynamo/output_graph.py:436 in init_ambient_guards
V0227 18:02:39.585000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] check_tensor(L['u'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float64, device=0, requires_grad=False, size=[None, None], stride=[None, 1])  # assert len(u.shape) == 2  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc
V0227 18:02:39.586000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['u'].size()[1] == L['u'].size()[0]                          # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.587000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['u'].stride()[0] == L['u'].size()[0]                        # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.587000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['ny'] == 300                                                # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.588000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['nx'] == 300                                                # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.588000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['u'].size()[0] > 299                                        # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.588000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] 300 < L['u'].size()[0] + 1                                    # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.589000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] 299 < L['u'].size()[0]                                        # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.589000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['u'].size()[0]**2 < 2147483648                              # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.590000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] 299 <= L['u'].size()[0]                                       # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.590000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['u'].stride()[0] == L['u'].size()[0]                        # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.591000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['ny'] == 300                                                # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.591000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['nx'] == 300                                                # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.591000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['u'].size()[0] > 299                                        # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.592000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] 300 < L['u'].size()[0] + 1                                    # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.592000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] 299 < L['u'].size()[0]                                        # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.593000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['u'].size()[0]**2 < 2147483648                              # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.593000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] 299 <= L['u'].size()[0]                                       # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.673000 22699002779456 torch/_inductor/triton_heuristics.py:516] Benchmark all input configs for triton_, get:
V0227 18:02:39.673000 22699002779456 torch/_inductor/triton_heuristics.py:518] XBLOCK: 1024, num_warps: 4, num_ctas: 1, num_stages: 1, enable_warp_specialization: False, enable_persistent: False: 0.008544, nreg 46, nspill 0, #shared-mem 0
V0227 18:02:39.673000 22699002779456 torch/_inductor/triton_heuristics.py:518] XBLOCK: 512, num_warps: 8, num_ctas: 1, num_stages: 1, enable_warp_specialization: False, enable_persistent: False: 0.008000, nreg 39, nspill 0, #shared-mem 0
V0227 18:02:39.673000 22699002779456 torch/_inductor/triton_heuristics.py:911] Save heuristic tuning result to /scratch/tmp.24755961.konradha/torchinductor_konradha/rq/crq3m3grnclfckvkksxrf2jg73hagwieolxo3rlgu2z2v663afl3.best_config
V0227 18:02:39.764000 22699002779456 torch/_inductor/triton_heuristics.py:516] Benchmark all input configs for triton_, get:
V0227 18:02:39.765000 22699002779456 torch/_inductor/triton_heuristics.py:518] XBLOCK: 1024, num_warps: 4, num_ctas: 1, num_stages: 1, enable_warp_specialization: False, enable_persistent: False: 0.012288, nreg 48, nspill 0, #shared-mem 0
V0227 18:02:39.765000 22699002779456 torch/_inductor/triton_heuristics.py:518] XBLOCK: 512, num_warps: 8, num_ctas: 1, num_stages: 1, enable_warp_specialization: False, enable_persistent: False: 0.011936, nreg 32, nspill 0, #shared-mem 0
V0227 18:02:39.765000 22699002779456 torch/_inductor/triton_heuristics.py:911] Save heuristic tuning result to /scratch/tmp.24755961.konradha/torchinductor_konradha/uv/cuvi747mgngom33pwxvrie4po5isymwvermlnz5tybblus7yhtl5.best_config
V0227 18:02:39.766000 22699002779456 torch/_dynamo/convert_frame.py:652] [0/0] torchdynamo start compiling neumann_bc /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:18, stack (elided 5 frames):
V0227 18:02:39.766000 22699002779456 torch/_dynamo/convert_frame.py:652] [0/0]   File "/cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py", line 59, in <module>
V0227 18:02:39.766000 22699002779456 torch/_dynamo/convert_frame.py:652] [0/0]     explanation = dynamo.explain(compiled_fn)(test_tensor, nx, ny)
V0227 18:02:39.766000 22699002779456 torch/_dynamo/convert_frame.py:652] [0/0]   File "/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 728, in inner
V0227 18:02:39.766000 22699002779456 torch/_dynamo/convert_frame.py:652] [0/0]     opt_f(*args, **kwargs)
V0227 18:02:39.766000 22699002779456 torch/_dynamo/convert_frame.py:652] [0/0]   File "/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 451, in _fn
V0227 18:02:39.766000 22699002779456 torch/_dynamo/convert_frame.py:652] [0/0]     return fn(*args, **kwargs)
V0227 18:02:39.766000 22699002779456 torch/_dynamo/convert_frame.py:652] [0/0] 
I0227 18:02:39.781000 22699002779456 torch/_dynamo/logging.py:55] [0/0] Step 1: torchdynamo start tracing neumann_bc /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:18
V0227 18:02:39.781000 22699002779456 torch/fx/experimental/symbolic_shapes.py:1980] [0/0] create_env
V0227 18:02:39.782000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:18 in neumann_bc (neumann_bc)
V0227 18:02:39.782000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]     def neumann_bc(u: torch.Tensor, nx: int, ny: int) -> torch.Tensor:
V0227 18:02:39.783000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE RESUME 0 []
V0227 18:02:39.783000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc (neumann_bc)
V0227 18:02:39.783000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         assert len(u.shape) == 2
V0227 18:02:39.783000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_GLOBAL len []
V0227 18:02:39.783000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [NullVariable(), BuiltinVariable()]
V0227 18:02:39.784000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_ATTR shape [NullVariable(), BuiltinVariable(), LazyVariableTracker()]
V0227 18:02:39.784000 22699002779456 torch/_dynamo/output_graph.py:1959] [0/0] create_graph_input L_u_ L['u']
V0227 18:02:39.785000 22699002779456 torch/_dynamo/variables/builder.py:1873] [0/0] wrap_to_fake L['u'] (300, 300) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.DYNAMIC: 0>, <DimDynamic.DYNAMIC: 0>], constraint_sizes=[None, None], view_base_context=None, tensor_source=LocalSource(local_name='u', cell_or_freevar=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>
I0227 18:02:39.789000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2724] [0/0] create_symbol s0 = 300 for L['u'].size()[0] [2, 9223372036854775806] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc (_dynamo/variables/builder.py:1881 in <lambda>)
I0227 18:02:39.793000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2724] [0/0] create_symbol s1 = 300 for L['u'].size()[1] [2, 9223372036854775806] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc (_dynamo/variables/builder.py:1881 in <lambda>)
V0227 18:02:39.794000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval True == True [statically known]
V0227 18:02:39.795000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval False == False [statically known]
V0227 18:02:39.798000 22699002779456 torch/_dynamo/output_graph.py:658] [0/0] bind_symint s0 L['u'].size()[0]
V0227 18:02:39.798000 22699002779456 torch/_dynamo/output_graph.py:1959] [0/0] create_graph_input s0 L['u'].size()[0]
V0227 18:02:39.798000 22699002779456 torch/_dynamo/output_graph.py:658] [0/0] bind_symint s1 L['u'].size()[1]
V0227 18:02:39.798000 22699002779456 torch/_dynamo/output_graph.py:1959] [0/0] create_graph_input s1 L['u'].size()[1]
V0227 18:02:39.798000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call size from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc (neumann_bc)
V0227 18:02:39.798000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     assert len(u.shape) == 2
V0227 18:02:39.798000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                ^^^^^^^
V0227 18:02:39.799000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE PRECALL 1 [NullVariable(), BuiltinVariable(), SizeVariable()]
V0227 18:02:39.799000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE CALL 1 [NullVariable(), BuiltinVariable(), SizeVariable()]
V0227 18:02:39.800000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 2 [ConstantVariable()]
V0227 18:02:39.800000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE COMPARE_OP == [ConstantVariable(), ConstantVariable()]
V0227 18:02:39.800000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE POP_JUMP_FORWARD_IF_TRUE 54 [ConstantVariable()]
V0227 18:02:39.800000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (neumann_bc)
V0227 18:02:39.800000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:02:39.800000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:02:39.800000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker()]
V0227 18:02:39.800000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), ConstantVariable()]
V0227 18:02:39.800000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:02:39.800000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker()]
V0227 18:02:39.800000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:39.801000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), ConstantVariable()]
V0227 18:02:39.801000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [LazyVariableTracker(), ConstantVariable(), SliceVariable()]
V0227 18:02:39.801000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_SUBSCR None [LazyVariableTracker(), TupleVariable()]
V0227 18:02:39.801000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call getitem_2 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (neumann_bc)
V0227 18:02:39.801000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:02:39.801000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                       ~^^^^^^^^^^^
V0227 18:02:39.803000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 > 1 == True [statically known]
V0227 18:02:39.804000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval False == False [statically known]
V0227 18:02:39.804000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 <= 1 == False [statically known]
I0227 18:02:39.808000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s1 >= 299 [guard added] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (_decomp/decompositions.py:756 in slice_forward)
V0227 18:02:39.809000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [TensorVariable()]
V0227 18:02:39.809000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 0 [TensorVariable(), LazyVariableTracker()]
V0227 18:02:39.809000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:39.809000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:02:39.809000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker()]
V0227 18:02:39.809000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:39.809000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), ConstantVariable()]
V0227 18:02:39.809000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), SliceVariable()]
V0227 18:02:39.809000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE STORE_SUBSCR None [TensorVariable(), LazyVariableTracker(), TupleVariable()]
V0227 18:02:39.810000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call setitem from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (neumann_bc)
V0227 18:02:39.810000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:02:39.810000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     ~^^^^^^^^^^^
V0227 18:02:39.810000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:02:39.810000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:02:39.810000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:02:39.810000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST nx [LazyVariableTracker()]
V0227 18:02:39.810000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 2 [LazyVariableTracker(), LazyVariableTracker()]
V0227 18:02:39.810000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [LazyVariableTracker(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:39.810000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), ConstantVariable()]
V0227 18:02:39.810000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:02:39.811000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker()]
V0227 18:02:39.811000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:39.811000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), ConstantVariable()]
V0227 18:02:39.811000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [LazyVariableTracker(), ConstantVariable(), SliceVariable()]
V0227 18:02:39.811000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_SUBSCR None [LazyVariableTracker(), TupleVariable()]
V0227 18:02:39.811000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call getitem_3 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:02:39.811000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:02:39.811000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                       ~^^^^^^^^^^^^^^
I0227 18:02:39.815000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s0 > 298 [guard added] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (_dynamo/utils.py:1764 in run_node)
V0227 18:02:39.816000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 <= 298 == False [statically known]
V0227 18:02:39.817000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [TensorVariable()]
V0227 18:02:39.817000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST nx [TensorVariable(), LazyVariableTracker()]
V0227 18:02:39.817000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), LazyVariableTracker()]
V0227 18:02:39.817000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [TensorVariable(), LazyVariableTracker(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:39.817000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:39.818000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:02:39.818000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker()]
V0227 18:02:39.818000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:39.818000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), ConstantVariable()]
V0227 18:02:39.818000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), SliceVariable()]
V0227 18:02:39.818000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE STORE_SUBSCR None [TensorVariable(), LazyVariableTracker(), TupleVariable()]
V0227 18:02:39.818000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call setitem_1 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:02:39.818000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:02:39.818000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     ~^^^^^^^^^^^^^^
V0227 18:02:39.819000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc (neumann_bc)
V0227 18:02:39.819000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         u[:, 0]    = u[:, 1]
V0227 18:02:39.819000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:02:39.819000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [LazyVariableTracker()]
V0227 18:02:39.819000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [LazyVariableTracker(), ConstantVariable()]
V0227 18:02:39.819000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:02:39.819000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), SliceVariable()]
V0227 18:02:39.819000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [LazyVariableTracker(), SliceVariable(), ConstantVariable()]
V0227 18:02:39.819000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_SUBSCR None [LazyVariableTracker(), TupleVariable()]
V0227 18:02:39.820000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call getitem_4 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc (neumann_bc)
V0227 18:02:39.820000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, 0]    = u[:, 1]
V0227 18:02:39.820000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                  ~^^^^^^
V0227 18:02:39.824000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval Eq(s0, 9223372036854775807) == False [statically known]
V0227 18:02:39.826000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 < 9223372036854775807 == True [statically known]
V0227 18:02:39.829000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s1 > 1 == True [statically known]
V0227 18:02:39.830000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s1 <= 1 == False [statically known]
V0227 18:02:39.831000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [TensorVariable()]
V0227 18:02:39.831000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [TensorVariable(), LazyVariableTracker()]
V0227 18:02:39.831000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [TensorVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:39.831000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:02:39.831000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 0 [TensorVariable(), LazyVariableTracker(), SliceVariable()]
V0227 18:02:39.831000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [TensorVariable(), LazyVariableTracker(), SliceVariable(), ConstantVariable()]
V0227 18:02:39.831000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE STORE_SUBSCR None [TensorVariable(), LazyVariableTracker(), TupleVariable()]
V0227 18:02:39.831000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call setitem_2 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc (neumann_bc)
V0227 18:02:39.831000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, 0]    = u[:, 1]
V0227 18:02:39.831000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     ~^^^^^^
V0227 18:02:39.832000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (neumann_bc)
V0227 18:02:39.832000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         u[:, ny-1] = u[:, ny-2]
V0227 18:02:39.832000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:02:39.832000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [LazyVariableTracker()]
V0227 18:02:39.832000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [LazyVariableTracker(), ConstantVariable()]
V0227 18:02:39.832000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:02:39.832000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [LazyVariableTracker(), SliceVariable()]
V0227 18:02:39.832000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 2 [LazyVariableTracker(), SliceVariable(), LazyVariableTracker()]
V0227 18:02:39.832000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [LazyVariableTracker(), SliceVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:39.832000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [LazyVariableTracker(), SliceVariable(), ConstantVariable()]
V0227 18:02:39.832000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_SUBSCR None [LazyVariableTracker(), TupleVariable()]
V0227 18:02:39.833000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call getitem_5 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (neumann_bc)
V0227 18:02:39.833000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, ny-1] = u[:, ny-2]
V0227 18:02:39.833000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                  ~^^^^^^^^^
V0227 18:02:39.837000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s1 > 298 == True [statically known]
V0227 18:02:39.838000 22699002779456 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s1 <= 298 == False [statically known]
V0227 18:02:39.839000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [TensorVariable()]
V0227 18:02:39.839000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [TensorVariable(), LazyVariableTracker()]
V0227 18:02:39.839000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [TensorVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:39.839000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:02:39.839000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [TensorVariable(), LazyVariableTracker(), SliceVariable()]
V0227 18:02:39.839000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), SliceVariable(), LazyVariableTracker()]
V0227 18:02:39.839000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [TensorVariable(), LazyVariableTracker(), SliceVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:02:39.839000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [TensorVariable(), LazyVariableTracker(), SliceVariable(), ConstantVariable()]
V0227 18:02:39.839000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE STORE_SUBSCR None [TensorVariable(), LazyVariableTracker(), TupleVariable()]
V0227 18:02:39.840000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call setitem_3 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (neumann_bc)
V0227 18:02:39.840000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, ny-1] = u[:, ny-2]
V0227 18:02:39.840000 22699002779456 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     ~^^^^^^^^^
V0227 18:02:39.840000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:27 in neumann_bc (neumann_bc)
V0227 18:02:39.840000 22699002779456 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         return u
V0227 18:02:39.840000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:02:39.840000 22699002779456 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE RETURN_VALUE None [LazyVariableTracker()]
I0227 18:02:39.840000 22699002779456 torch/_dynamo/logging.py:55] [0/0] Step 1: torchdynamo done tracing neumann_bc (RETURN_VALUE)
V0227 18:02:39.840000 22699002779456 torch/_dynamo/symbolic_convert.py:2267] [0/0] RETURN_VALUE triggered compile
V0227 18:02:39.840000 22699002779456 torch/_dynamo/output_graph.py:871] [0/0] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py, line 27 in neumann_bc>], graph_break=False)
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code] TRACED GRAPH
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]  ===== __compiled_fn_1 =====
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]  /cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]     def forward(self, s0 : torch.SymInt, s1 : torch.SymInt, L_u_ : torch.Tensor):
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_ = L_u_
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc, code: assert len(u.shape) == 2
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         size = l_u_.size()
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc, code: u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         getitem_2 = l_u_[(1, slice(1, 299, None))]
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_[(0, slice(1, 299, None))] = getitem_2;  setitem = l_u_;  getitem_2 = None
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc, code: u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         getitem_3 = l_u_[(298, slice(1, 299, None))]
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_[(299, slice(1, 299, None))] = getitem_3;  setitem_1 = l_u_;  getitem_3 = None
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc, code: u[:, 0]    = u[:, 1]
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         getitem_4 = l_u_[(slice(None, None, None), 1)]
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_[(slice(None, None, None), 0)] = getitem_4;  setitem_2 = l_u_;  getitem_4 = None
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc, code: u[:, ny-1] = u[:, ny-2]
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         getitem_5 = l_u_[(slice(None, None, None), 298)]
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_[(slice(None, None, None), 299)] = getitem_5;  setitem_3 = l_u_;  getitem_5 = None
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         return (l_u_,)
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:02:39.841000 22699002779456 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code] 
V0227 18:02:39.843000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] TRACED GRAPH
V0227 18:02:39.843000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph]  __compiled_fn_1 /cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/fx/_lazy_graph_module.py opcode         name       target                       args                                               kwargs
V0227 18:02:39.843000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] -------------  ---------  ---------------------------  -------------------------------------------------  --------
V0227 18:02:39.843000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] placeholder    s0         s0                           ()                                                 {}
V0227 18:02:39.843000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] placeholder    s1         s1                           ()                                                 {}
V0227 18:02:39.843000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] placeholder    l_u_       L_u_                         ()                                                 {}
V0227 18:02:39.843000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_method    size       size                         (l_u_,)                                            {}
V0227 18:02:39.843000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  getitem_2  <built-in function getitem>  (l_u_, (1, slice(1, 299, None)))                   {}
V0227 18:02:39.843000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  setitem    <built-in function setitem>  (l_u_, (0, slice(1, 299, None)), getitem_2)        {}
V0227 18:02:39.843000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  getitem_3  <built-in function getitem>  (l_u_, (298, slice(1, 299, None)))                 {}
V0227 18:02:39.843000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  setitem_1  <built-in function setitem>  (l_u_, (299, slice(1, 299, None)), getitem_3)      {}
V0227 18:02:39.843000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  getitem_4  <built-in function getitem>  (l_u_, (slice(None, None, None), 1))               {}
V0227 18:02:39.843000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  setitem_2  <built-in function setitem>  (l_u_, (slice(None, None, None), 0), getitem_4)    {}
V0227 18:02:39.843000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  getitem_5  <built-in function getitem>  (l_u_, (slice(None, None, None), 298))             {}
V0227 18:02:39.843000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  setitem_3  <built-in function setitem>  (l_u_, (slice(None, None, None), 299), getitem_5)  {}
V0227 18:02:39.843000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] output         output     output                       ((l_u_,),)                                         {}
V0227 18:02:39.843000 22699002779456 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] 
V0227 18:02:39.846000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] TRACED GRAPH TENSOR SIZES
V0227 18:02:39.846000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] ===== __compiled_fn_1 =====
V0227 18:02:39.846000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] l_u_: (s0, s1)
V0227 18:02:39.846000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] l_u_ (concrete): (300, 300)
V0227 18:02:39.846000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_2: (298,)
V0227 18:02:39.846000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_3: (298,)
V0227 18:02:39.846000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_4: (s0,)
V0227 18:02:39.846000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_4 (concrete): (300,)
V0227 18:02:39.846000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_5: (s0,)
V0227 18:02:39.846000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_5 (concrete): (300,)
V0227 18:02:39.846000 22699002779456 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] 
I0227 18:02:39.846000 22699002779456 torch/_dynamo/logging.py:55] [0/0] Step 2: calling compiler function dynamo_graph_accumulating_compiler
I0227 18:02:39.846000 22699002779456 torch/_dynamo/logging.py:55] [0/0] Step 2: done compiler function dynamo_graph_accumulating_compiler
I0227 18:02:39.862000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2806] [0/0] produce_guards
V0227 18:02:39.862000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].size()[0] s0 None
V0227 18:02:39.862000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].size()[1] s1 None
V0227 18:02:39.862000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].stride()[0] s1 None
V0227 18:02:39.863000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].stride()[1] 1 None
V0227 18:02:39.863000 22699002779456 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].storage_offset() 0 None
V0227 18:02:39.863000 22699002779456 torch/fx/experimental/symbolic_shapes.py:3138] [0/0] Skipping guard L['u'].stride()[1] == 1
V0227 18:02:39.863000 22699002779456 torch/fx/experimental/symbolic_shapes.py:3138] [0/0] Skipping guard L['u'].storage_offset() == 0
V0227 18:02:39.868000 22699002779456 torch/_dynamo/guards.py:1076] [0/0] [__guards] GUARDS:
V0227 18:02:39.868000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] ___check_type_id(L['u'], 78718768)                            # assert len(u.shape) == 2  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc
V0227 18:02:39.868000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] hasattr(L['u'], '_dynamo_dynamic_indices') == False           # assert len(u.shape) == 2  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc
V0227 18:02:39.868000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] ___check_type_id(L['nx'], 22699011583200)                     # u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc
V0227 18:02:39.869000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['nx'] == 300                                                # u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc
V0227 18:02:39.869000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] ___check_type_id(L['ny'], 22699011583200)                     # u[0, 1:ny-1]    = u[1, 1:ny-1]  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc
V0227 18:02:39.869000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['ny'] == 300                                                # u[0, 1:ny-1]    = u[1, 1:ny-1]  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc
V0227 18:02:39.869000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:430 in init_ambient_guards
V0227 18:02:39.870000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] ___check_current_backend(22696011559328)                      # _dynamo/output_graph.py:436 in init_ambient_guards
V0227 18:02:39.870000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] check_tensor(L['u'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float64, device=0, requires_grad=False, size=[None, None], stride=[None, 1])  # assert len(u.shape) == 2  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc
V0227 18:02:39.870000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['u'].stride()[0] == L['u'].size()[1]                        # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.871000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] 299 <= L['u'].size()[0]                                       # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.871000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] 299 <= L['u'].size()[1]                                       # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.871000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] 299 <= L['u'].size()[0]                                       # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:02:39.871000 22699002779456 torch/_dynamo/guards.py:1085] [0/0] [__guards] 299 <= L['u'].size()[1]                                       # _dynamo/output_graph.py:422 in init_ambient_guards
I0227 18:02:39.992000 22699002779456 torch/_dynamo/utils.py:320] TorchDynamo compilation metrics:
I0227 18:02:39.992000 22699002779456 torch/_dynamo/utils.py:320] Function    Runtimes (s)
I0227 18:02:39.992000 22699002779456 torch/_dynamo/utils.py:320] ----------  --------------
I0227 18:03:00.187000 22563112417088 torch/_dynamo/logging.py:55] [0/0] Step 1: torchdynamo start tracing neumann_bc /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:18
V0227 18:03:00.189000 22563112417088 torch/fx/experimental/symbolic_shapes.py:1980] [0/0] create_env
V0227 18:03:00.230000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:18 in neumann_bc (neumann_bc)
V0227 18:03:00.230000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]     def neumann_bc(u: torch.Tensor, nx: int, ny: int) -> torch.Tensor:
V0227 18:03:07.743000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE RESUME 0 []
V0227 18:03:07.748000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc (neumann_bc)
V0227 18:03:07.748000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         assert len(u.shape) == 2
V0227 18:03:07.748000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_GLOBAL len []
V0227 18:03:07.750000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [NullVariable(), BuiltinVariable()]
V0227 18:03:07.751000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_ATTR shape [NullVariable(), BuiltinVariable(), LazyVariableTracker()]
V0227 18:03:07.751000 22563112417088 torch/_dynamo/output_graph.py:1959] [0/0] create_graph_input L_u_ L['u']
V0227 18:03:07.778000 22563112417088 torch/_dynamo/variables/builder.py:1873] [0/0] wrap_to_fake L['u'] (300, 300) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.DUCK: 1>, <DimDynamic.DUCK: 1>], constraint_sizes=[None, None], view_base_context=None, tensor_source=LocalSource(local_name='u', cell_or_freevar=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>
I0227 18:03:07.969000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2724] [0/0] create_symbol s0 = 300 for L['u'].size()[0] [2, 9223372036854775806] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc (_dynamo/variables/builder.py:1881 in <lambda>)
V0227 18:03:07.970000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2735] [0/0] create_symbol s0 duck sized L['u'].size()[1]
V0227 18:03:07.973000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval True == True [statically known]
V0227 18:03:07.974000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval False == False [statically known]
V0227 18:03:07.981000 22563112417088 torch/_dynamo/output_graph.py:658] [0/0] bind_symint s0 L['u'].size()[0]
V0227 18:03:07.981000 22563112417088 torch/_dynamo/output_graph.py:1959] [0/0] create_graph_input s0 L['u'].size()[0]
V0227 18:03:07.982000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call size from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc (neumann_bc)
V0227 18:03:07.982000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     assert len(u.shape) == 2
V0227 18:03:07.982000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                ^^^^^^^
V0227 18:03:07.983000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE PRECALL 1 [NullVariable(), BuiltinVariable(), SizeVariable()]
V0227 18:03:07.983000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE CALL 1 [NullVariable(), BuiltinVariable(), SizeVariable()]
V0227 18:03:07.983000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 2 [ConstantVariable()]
V0227 18:03:07.983000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE COMPARE_OP == [ConstantVariable(), ConstantVariable()]
V0227 18:03:07.983000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE POP_JUMP_FORWARD_IF_TRUE 54 [ConstantVariable()]
V0227 18:03:07.984000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (neumann_bc)
V0227 18:03:07.984000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:03:07.984000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:03:07.984000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker()]
V0227 18:03:07.984000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), ConstantVariable()]
V0227 18:03:07.984000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:03:07.984000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker()]
V0227 18:03:07.984000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker(), ConstantVariable()]
I0227 18:03:07.985000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2724] [0/0] create_symbol s1 = 300 for L['ny'] [-9223372036854775808, 9223372036854775807] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (_dynamo/variables/builder.py:1241 in wrap_unspecialized_primitive)
V0227 18:03:07.985000 22563112417088 torch/_dynamo/output_graph.py:1959] [0/0] create_graph_input L_ny_ L['ny']
V0227 18:03:07.986000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call sub from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (neumann_bc)
V0227 18:03:07.986000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:03:07.986000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                              ~~^^
V0227 18:03:07.986000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), SymNodeVariable()]
V0227 18:03:07.987000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [LazyVariableTracker(), ConstantVariable(), SliceVariable()]
V0227 18:03:07.987000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_SUBSCR None [LazyVariableTracker(), TupleVariable()]
V0227 18:03:07.987000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call getitem_2 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (neumann_bc)
V0227 18:03:07.987000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:03:07.987000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                       ~^^^^^^^^^^^
V0227 18:03:07.991000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 > 1 == True [statically known]
V0227 18:03:07.992000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval False == False [statically known]
V0227 18:03:07.993000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 <= 1 == False [statically known]
I0227 18:03:08.015000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s1 - 1 >= 0 [guard added] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (_decomp/decompositions.py:746 in slice_forward)
I0227 18:03:08.023000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s1 - 1 >= 1 [guard added] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (_decomp/decompositions.py:754 in slice_forward)
I0227 18:03:08.032000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s1 - 1 <= s0 [guard added] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (_decomp/decompositions.py:756 in slice_forward)
V0227 18:03:08.034000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [TensorVariable()]
V0227 18:03:08.034000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 0 [TensorVariable(), LazyVariableTracker()]
V0227 18:03:08.034000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:08.035000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:03:08.035000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker()]
V0227 18:03:08.035000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:08.035000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call sub_1 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (neumann_bc)
V0227 18:03:08.035000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:03:08.035000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]            ~~^^
V0227 18:03:08.036000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), SymNodeVariable()]
V0227 18:03:08.036000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), SliceVariable()]
V0227 18:03:08.036000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE STORE_SUBSCR None [TensorVariable(), LazyVariableTracker(), TupleVariable()]
V0227 18:03:08.036000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call setitem from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (neumann_bc)
V0227 18:03:08.036000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:03:08.036000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     ~^^^^^^^^^^^
V0227 18:03:08.037000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:03:08.037000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:03:08.037000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:03:08.037000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST nx [LazyVariableTracker()]
V0227 18:03:08.037000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 2 [LazyVariableTracker(), LazyVariableTracker()]
V0227 18:03:08.037000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [LazyVariableTracker(), LazyVariableTracker(), ConstantVariable()]
I0227 18:03:08.037000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2724] [0/0] create_symbol s2 = 300 for L['nx'] [-9223372036854775808, 9223372036854775807] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (_dynamo/variables/builder.py:1241 in wrap_unspecialized_primitive)
V0227 18:03:08.038000 22563112417088 torch/_dynamo/output_graph.py:1959] [0/0] create_graph_input L_nx_ L['nx']
V0227 18:03:08.038000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call sub_2 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:03:08.038000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:03:08.038000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                         ~~^^
V0227 18:03:08.039000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), SymNodeVariable()]
V0227 18:03:08.039000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [LazyVariableTracker(), SymNodeVariable(), ConstantVariable()]
V0227 18:03:08.039000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), SymNodeVariable(), ConstantVariable(), LazyVariableTracker()]
V0227 18:03:08.039000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [LazyVariableTracker(), SymNodeVariable(), ConstantVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:08.039000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call sub_3 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:03:08.039000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:03:08.039000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                                 ~~^^
V0227 18:03:08.040000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [LazyVariableTracker(), SymNodeVariable(), ConstantVariable(), SymNodeVariable()]
V0227 18:03:08.040000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [LazyVariableTracker(), SymNodeVariable(), SliceVariable()]
V0227 18:03:08.040000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_SUBSCR None [LazyVariableTracker(), TupleVariable()]
V0227 18:03:08.040000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call getitem_3 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:03:08.040000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:03:08.040000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                       ~^^^^^^^^^^^^^^
I0227 18:03:08.045000 22563112417088 torch/fx/experimental/symbolic_shapes.py:3809] [0/0] set_replacement s2 = 300 (solve_backed) ValueRanges(lower=300, upper=300, is_bool=False)
I0227 18:03:08.045000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval Eq(s2 - 2, 298) [guard added] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (_dynamo/utils.py:1764 in run_node)
I0227 18:03:08.053000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s0 > 298 [guard added] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (_dynamo/utils.py:1764 in run_node)
V0227 18:03:08.054000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 <= 298 == False [statically known]
V0227 18:03:08.057000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [TensorVariable()]
V0227 18:03:08.057000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST nx [TensorVariable(), LazyVariableTracker()]
V0227 18:03:08.057000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), LazyVariableTracker()]
V0227 18:03:08.057000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [TensorVariable(), LazyVariableTracker(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:08.058000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call sub_4 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:03:08.058000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:03:08.058000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]       ~~^^
I0227 18:03:08.060000 22563112417088 torch/fx/experimental/symbolic_shapes.py:3809] [0/0] set_replacement s2 = 300 (find) ValueRanges(lower=300, upper=300, is_bool=False)
V0227 18:03:08.060000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), SymNodeVariable()]
V0227 18:03:08.060000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [TensorVariable(), LazyVariableTracker(), SymNodeVariable(), ConstantVariable()]
V0227 18:03:08.060000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), SymNodeVariable(), ConstantVariable(), LazyVariableTracker()]
V0227 18:03:08.061000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [TensorVariable(), LazyVariableTracker(), SymNodeVariable(), ConstantVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:08.061000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call sub_5 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:03:08.061000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:03:08.061000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]               ~~^^
V0227 18:03:08.061000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [TensorVariable(), LazyVariableTracker(), SymNodeVariable(), ConstantVariable(), SymNodeVariable()]
V0227 18:03:08.061000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [TensorVariable(), LazyVariableTracker(), SymNodeVariable(), SliceVariable()]
V0227 18:03:08.062000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE STORE_SUBSCR None [TensorVariable(), LazyVariableTracker(), TupleVariable()]
V0227 18:03:08.062000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call setitem_1 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:03:08.062000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:03:08.062000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     ~^^^^^^^^^^^^^^
V0227 18:03:08.062000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc (neumann_bc)
V0227 18:03:08.062000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         u[:, 0]    = u[:, 1]
V0227 18:03:08.062000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:03:08.062000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [LazyVariableTracker()]
V0227 18:03:08.062000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [LazyVariableTracker(), ConstantVariable()]
V0227 18:03:08.063000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:03:08.063000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), SliceVariable()]
V0227 18:03:08.063000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [LazyVariableTracker(), SliceVariable(), ConstantVariable()]
V0227 18:03:08.063000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_SUBSCR None [LazyVariableTracker(), TupleVariable()]
V0227 18:03:08.063000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call getitem_4 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc (neumann_bc)
V0227 18:03:08.063000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, 0]    = u[:, 1]
V0227 18:03:08.063000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                  ~^^^^^^
V0227 18:03:08.069000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval Eq(s0, 9223372036854775807) == False [statically known]
V0227 18:03:08.071000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 < 9223372036854775807 == True [statically known]
V0227 18:03:08.072000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [TensorVariable()]
V0227 18:03:08.072000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [TensorVariable(), LazyVariableTracker()]
V0227 18:03:08.073000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [TensorVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:08.073000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:03:08.073000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 0 [TensorVariable(), LazyVariableTracker(), SliceVariable()]
V0227 18:03:08.073000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [TensorVariable(), LazyVariableTracker(), SliceVariable(), ConstantVariable()]
V0227 18:03:08.073000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE STORE_SUBSCR None [TensorVariable(), LazyVariableTracker(), TupleVariable()]
V0227 18:03:08.073000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call setitem_2 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc (neumann_bc)
V0227 18:03:08.073000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, 0]    = u[:, 1]
V0227 18:03:08.073000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     ~^^^^^^
V0227 18:03:08.074000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (neumann_bc)
V0227 18:03:08.074000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         u[:, ny-1] = u[:, ny-2]
V0227 18:03:08.074000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:03:08.074000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [LazyVariableTracker()]
V0227 18:03:08.074000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [LazyVariableTracker(), ConstantVariable()]
V0227 18:03:08.074000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:03:08.074000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [LazyVariableTracker(), SliceVariable()]
V0227 18:03:08.074000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 2 [LazyVariableTracker(), SliceVariable(), LazyVariableTracker()]
V0227 18:03:08.074000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [LazyVariableTracker(), SliceVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:08.075000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call sub_6 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (neumann_bc)
V0227 18:03:08.075000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, ny-1] = u[:, ny-2]
V0227 18:03:08.075000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                       ~~^^
V0227 18:03:08.075000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [LazyVariableTracker(), SliceVariable(), SymNodeVariable()]
V0227 18:03:08.075000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_SUBSCR None [LazyVariableTracker(), TupleVariable()]
V0227 18:03:08.076000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call getitem_5 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (neumann_bc)
V0227 18:03:08.076000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, ny-1] = u[:, ny-2]
V0227 18:03:08.076000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                  ~^^^^^^^^^
I0227 18:03:08.080000 22563112417088 torch/fx/experimental/symbolic_shapes.py:3809] [0/0] set_replacement s1 = 300 (solve_backed) ValueRanges(lower=300, upper=300, is_bool=False)
I0227 18:03:08.081000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval Eq(s1 - 2, 298) [guard added] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (_dynamo/utils.py:1764 in run_node)
V0227 18:03:08.082000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [TensorVariable()]
V0227 18:03:08.082000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [TensorVariable(), LazyVariableTracker()]
V0227 18:03:08.082000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [TensorVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:08.082000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:03:08.082000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [TensorVariable(), LazyVariableTracker(), SliceVariable()]
V0227 18:03:08.082000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), SliceVariable(), LazyVariableTracker()]
V0227 18:03:08.083000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [TensorVariable(), LazyVariableTracker(), SliceVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:08.083000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call sub_7 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (neumann_bc)
V0227 18:03:08.083000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, ny-1] = u[:, ny-2]
V0227 18:03:08.083000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]          ~~^^
I0227 18:03:08.085000 22563112417088 torch/fx/experimental/symbolic_shapes.py:3809] [0/0] set_replacement s1 = 300 (find) ValueRanges(lower=300, upper=300, is_bool=False)
V0227 18:03:08.085000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [TensorVariable(), LazyVariableTracker(), SliceVariable(), SymNodeVariable()]
V0227 18:03:08.085000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE STORE_SUBSCR None [TensorVariable(), LazyVariableTracker(), TupleVariable()]
V0227 18:03:08.086000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call setitem_3 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (neumann_bc)
V0227 18:03:08.086000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, ny-1] = u[:, ny-2]
V0227 18:03:08.086000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     ~^^^^^^^^^
V0227 18:03:08.086000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:27 in neumann_bc (neumann_bc)
V0227 18:03:08.086000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         return u
V0227 18:03:08.086000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:03:08.086000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE RETURN_VALUE None [LazyVariableTracker()]
I0227 18:03:08.086000 22563112417088 torch/_dynamo/logging.py:55] [0/0] Step 1: torchdynamo done tracing neumann_bc (RETURN_VALUE)
V0227 18:03:08.086000 22563112417088 torch/_dynamo/symbolic_convert.py:2267] [0/0] RETURN_VALUE triggered compile
V0227 18:03:08.086000 22563112417088 torch/_dynamo/output_graph.py:871] [0/0] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py, line 27 in neumann_bc>], graph_break=False)
I0227 18:03:08.089000 22563112417088 torch/fx/experimental/symbolic_shapes.py:3809] [0/0] set_replacement s2 = 300 (find) ValueRanges(lower=300, upper=300, is_bool=False)
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code] TRACED GRAPH
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]  ===== __compiled_fn_0 =====
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]  /cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]     def forward(self, s0 : torch.SymInt, L_u_ : torch.Tensor, L_ny_ : torch.SymInt, L_nx_ : torch.SymInt):
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_ = L_u_
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_ny_ = L_ny_
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_nx_ = L_nx_
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc, code: assert len(u.shape) == 2
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         size = l_u_.size()
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc, code: u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         sub = l_ny_ - 1
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         getitem_2 = l_u_[(1, slice(1, sub, None))];  sub = None
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         sub_1 = l_ny_ - 1
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_[(0, slice(1, sub_1, None))] = getitem_2;  setitem = l_u_;  sub_1 = getitem_2 = None
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc, code: u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         sub_2 = l_nx_ - 2
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         sub_3 = l_ny_ - 1
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         getitem_3 = l_u_[(sub_2, slice(1, sub_3, None))];  sub_2 = sub_3 = None
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         sub_4 = l_nx_ - 1;  l_nx_ = None
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         sub_5 = l_ny_ - 1
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_[(sub_4, slice(1, sub_5, None))] = getitem_3;  setitem_1 = l_u_;  sub_4 = sub_5 = getitem_3 = None
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc, code: u[:, 0]    = u[:, 1]
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         getitem_4 = l_u_[(slice(None, None, None), 1)]
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_[(slice(None, None, None), 0)] = getitem_4;  setitem_2 = l_u_;  getitem_4 = None
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc, code: u[:, ny-1] = u[:, ny-2]
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         sub_6 = l_ny_ - 2
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         getitem_5 = l_u_[(slice(None, None, None), sub_6)];  sub_6 = None
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         sub_7 = l_ny_ - 1;  l_ny_ = None
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_[(slice(None, None, None), sub_7)] = getitem_5;  setitem_3 = l_u_;  sub_7 = getitem_5 = None
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         return (l_u_,)
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:03:08.089000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code] 
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] TRACED GRAPH
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph]  __compiled_fn_0 /cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/fx/_lazy_graph_module.py opcode         name       target                       args                                                 kwargs
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] -------------  ---------  ---------------------------  ---------------------------------------------------  --------
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] placeholder    s0         s0                           ()                                                   {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] placeholder    l_u_       L_u_                         ()                                                   {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] placeholder    l_ny_      L_ny_                        ()                                                   {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] placeholder    l_nx_      L_nx_                        ()                                                   {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_method    size       size                         (l_u_,)                                              {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  sub        <built-in function sub>      (l_ny_, 1)                                           {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  getitem_2  <built-in function getitem>  (l_u_, (1, slice(1, sub, None)))                     {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  sub_1      <built-in function sub>      (l_ny_, 1)                                           {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  setitem    <built-in function setitem>  (l_u_, (0, slice(1, sub_1, None)), getitem_2)        {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  sub_2      <built-in function sub>      (l_nx_, 2)                                           {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  sub_3      <built-in function sub>      (l_ny_, 1)                                           {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  getitem_3  <built-in function getitem>  (l_u_, (sub_2, slice(1, sub_3, None)))               {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  sub_4      <built-in function sub>      (l_nx_, 1)                                           {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  sub_5      <built-in function sub>      (l_ny_, 1)                                           {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  setitem_1  <built-in function setitem>  (l_u_, (sub_4, slice(1, sub_5, None)), getitem_3)    {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  getitem_4  <built-in function getitem>  (l_u_, (slice(None, None, None), 1))                 {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  setitem_2  <built-in function setitem>  (l_u_, (slice(None, None, None), 0), getitem_4)      {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  sub_6      <built-in function sub>      (l_ny_, 2)                                           {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  getitem_5  <built-in function getitem>  (l_u_, (slice(None, None, None), sub_6))             {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  sub_7      <built-in function sub>      (l_ny_, 1)                                           {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  setitem_3  <built-in function setitem>  (l_u_, (slice(None, None, None), sub_7), getitem_5)  {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] output         output     output                       ((l_u_,),)                                           {}
V0227 18:03:08.096000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] 
V0227 18:03:08.174000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] TRACED GRAPH TENSOR SIZES
V0227 18:03:08.174000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] ===== __compiled_fn_0 =====
V0227 18:03:08.174000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] l_u_: (s0, s0)
V0227 18:03:08.174000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] l_u_ (concrete): (300, 300)
V0227 18:03:08.174000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_2: (298,)
V0227 18:03:08.174000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_2 (concrete): (298,)
V0227 18:03:08.174000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_3: (298,)
V0227 18:03:08.174000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_3 (concrete): (298,)
V0227 18:03:08.174000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_4: (s0,)
V0227 18:03:08.174000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_4 (concrete): (300,)
V0227 18:03:08.174000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_5: (s0,)
V0227 18:03:08.174000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_5 (concrete): (300,)
V0227 18:03:08.174000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] 
I0227 18:03:08.175000 22563112417088 torch/_dynamo/logging.py:55] [0/0] Step 2: calling compiler function inductor
V0227 18:03:08.275000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval True == True [statically known]
V0227 18:03:08.280000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 < 299 == False [statically known]
V0227 18:03:08.816000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4107] [0/0] eval 298 [trivial]
V0227 18:03:08.822000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4107] [0/0] eval 299 [trivial]
I0227 18:03:08.833000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s0 > 299 [guard added] (_functorch/_aot_autograd/traced_function_transforms.py:651 in run_node)
I0227 18:03:08.836000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s0 > 299 [guard added] (_meta_registrations.py:4980 in meta_select)
V0227 18:03:08.865000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval Ne(s0, 1) == True [statically known]
V0227 18:03:08.865000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval Eq(s0, 1) == False [statically known]
V0227 18:03:08.867000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 < 2 == False [statically known]
V0227 18:03:08.867000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval Eq(s0, 1) == False [statically known]
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs] TRACED GRAPH
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]  ===== Forward graph 0 =====
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]  /cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/fx/_lazy_graph_module.py class <lambda>(torch.nn.Module):
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]     def forward(self, arg0_1: "Sym(s0)", arg1_1: "f64[s0, s0]", arg2_1: "Sym(300)", arg3_1: "Sym(300)"):
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc, code: u[0, 1:ny-1]    = u[1, 1:ny-1]
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select: "f64[s0]" = torch.ops.aten.select.int(arg1_1, 0, 1)
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_1: "f64[298]" = torch.ops.aten.slice.Tensor(select, 0, 1, 299);  select = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_1: "f64[s0]" = torch.ops.aten.select.int(arg1_1, 0, 0)
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_2: "f64[298]" = torch.ops.aten.slice.Tensor(select_1, 0, 1, 299);  select_1 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         copy: "f64[298]" = torch.ops.aten.copy.default(slice_2, slice_1);  slice_2 = slice_1 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_2: "f64[s0]" = torch.ops.aten.select.int(arg1_1, 0, 0)
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_scatter: "f64[s0]" = torch.ops.aten.slice_scatter.default(select_2, copy, 0, 1, 299);  select_2 = copy = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_scatter: "f64[s0, s0]" = torch.ops.aten.select_scatter.default(arg1_1, slice_scatter, 0, 0);  slice_scatter = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc, code: u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_6: "f64[s0]" = torch.ops.aten.select.int(select_scatter, 0, 299)
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_6: "f64[298]" = torch.ops.aten.slice.Tensor(select_6, 0, 1, 299);  select_6 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_7: "f64[s0]" = torch.ops.aten.select.int(select_scatter, 0, 298)
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_7: "f64[298]" = torch.ops.aten.slice.Tensor(select_7, 0, 1, 299);  select_7 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         copy_1: "f64[298]" = torch.ops.aten.copy.default(slice_6, slice_7);  slice_6 = slice_7 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_8: "f64[s0]" = torch.ops.aten.select.int(select_scatter, 0, 299)
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_scatter_1: "f64[s0]" = torch.ops.aten.slice_scatter.default(select_8, copy_1, 0, 1, 299);  select_8 = copy_1 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_scatter_1: "f64[s0, s0]" = torch.ops.aten.select_scatter.default(select_scatter, slice_scatter_1, 0, 299);  select_scatter = slice_scatter_1 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc, code: u[:, 0]    = u[:, 1]
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_11: "f64[s0, s0]" = torch.ops.aten.slice.Tensor(select_scatter_1, 0, 0, 9223372036854775807)
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_12: "f64[s0]" = torch.ops.aten.select.int(slice_11, 1, 0);  slice_11 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_12: "f64[s0, s0]" = torch.ops.aten.slice.Tensor(select_scatter_1, 0, 0, 9223372036854775807)
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_13: "f64[s0]" = torch.ops.aten.select.int(slice_12, 1, 1);  slice_12 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         copy_2: "f64[s0]" = torch.ops.aten.copy.default(select_12, select_13);  select_12 = select_13 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_13: "f64[s0, s0]" = torch.ops.aten.slice.Tensor(select_scatter_1, 0, 0, 9223372036854775807)
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_scatter_2: "f64[s0, s0]" = torch.ops.aten.select_scatter.default(slice_13, copy_2, 1, 0);  slice_13 = copy_2 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_scatter_2: "f64[s0, s0]" = torch.ops.aten.slice_scatter.default(select_scatter_1, select_scatter_2, 0, 0, 9223372036854775807);  select_scatter_1 = select_scatter_2 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc, code: u[:, ny-1] = u[:, ny-2]
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_17: "f64[s0, s0]" = torch.ops.aten.slice.Tensor(slice_scatter_2, 0, 0, 9223372036854775807)
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_17: "f64[s0]" = torch.ops.aten.select.int(slice_17, 1, 299);  slice_17 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_18: "f64[s0, s0]" = torch.ops.aten.slice.Tensor(slice_scatter_2, 0, 0, 9223372036854775807)
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_18: "f64[s0]" = torch.ops.aten.select.int(slice_18, 1, 298);  slice_18 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         copy_3: "f64[s0]" = torch.ops.aten.copy.default(select_17, select_18);  select_17 = select_18 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_19: "f64[s0, s0]" = torch.ops.aten.slice.Tensor(slice_scatter_2, 0, 0, 9223372036854775807)
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         select_scatter_3: "f64[s0, s0]" = torch.ops.aten.select_scatter.default(slice_19, copy_3, 1, 299);  slice_19 = copy_3 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         slice_scatter_3: "f64[s0, s0]" = torch.ops.aten.slice_scatter.default(slice_scatter_2, select_scatter_3, 0, 0, 9223372036854775807);  slice_scatter_2 = select_scatter_3 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         copy_: "f64[s0, s0]" = torch.ops.aten.copy_.default(arg1_1, slice_scatter_3);  arg1_1 = slice_scatter_3 = None
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         return (copy_,)
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs]         
I0227 18:03:09.106000 22563112417088 torch/_functorch/_aot_autograd/dispatch_and_compile_graph.py:109] [0/0] [__aot_graphs] 
I0227 18:03:09.670000 22563112417088 torch/_dynamo/logging.py:55] [0/0] Step 3: torchinductor compiling FORWARDS graph 0
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs] TRACED GRAPH
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]  ===== AFTER POST GRAD =====
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]  /cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/fx/_lazy_graph_module.py class <lambda>(torch.nn.Module):
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]     def forward(self, arg0_1: "Sym(s0)", arg1_1: "f64[s0, s0]", arg2_1: "Sym(300)", arg3_1: "Sym(300)"):
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc, code: u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_2: "f64[s0]" = torch.ops.aten.select.int(arg1_1, 0, 0)
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_1: "f64[s0]" = torch.ops.aten.select.int(arg1_1, 0, 0)
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         slice_2: "f64[298]" = torch.ops.aten.slice.Tensor(select_1, 0, 1, 299);  select_1 = None
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select: "f64[s0]" = torch.ops.aten.select.int(arg1_1, 0, 1)
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         slice_1: "f64[298]" = torch.ops.aten.slice.Tensor(select, 0, 1, 299);  select = None
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # No stacktrace found for following nodes
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_int: "f64[s0]" = torch.ops.aten.select.int(arg1_1, 0, 0)
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         slice_scatter_default: "f64[s0]" = torch.ops.aten.slice_scatter.default(select_int, slice_1, 0, 1, 299);  select_int = slice_1 = None
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_scatter_default: "f64[s0, s0]" = torch.ops.aten.select_scatter.default(arg1_1, slice_scatter_default, 0, 0);  slice_scatter_default = None
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc, code: u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_8: "f64[s0]" = torch.ops.aten.select.int(select_scatter_default, 0, 299)
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_6: "f64[s0]" = torch.ops.aten.select.int(select_scatter_default, 0, 299)
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         slice_6: "f64[298]" = torch.ops.aten.slice.Tensor(select_6, 0, 1, 299);  select_6 = None
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_7: "f64[s0]" = torch.ops.aten.select.int(select_scatter_default, 0, 298)
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         slice_7: "f64[298]" = torch.ops.aten.slice.Tensor(select_7, 0, 1, 299);  select_7 = None
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # No stacktrace found for following nodes
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_int_1: "f64[s0]" = torch.ops.aten.select.int(select_scatter_default, 0, 299)
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         slice_scatter_default_1: "f64[s0]" = torch.ops.aten.slice_scatter.default(select_int_1, slice_7, 0, 1, 299);  select_int_1 = slice_7 = None
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_scatter_default_1: "f64[s0, s0]" = torch.ops.aten.select_scatter.default(select_scatter_default, slice_scatter_default_1, 0, 299);  select_scatter_default = slice_scatter_default_1 = None
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc, code: u[:, 0]    = u[:, 1]
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_12: "f64[s0]" = torch.ops.aten.select.int(select_scatter_default_1, 1, 0)
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_13: "f64[s0]" = torch.ops.aten.select.int(select_scatter_default_1, 1, 1)
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # No stacktrace found for following nodes
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_scatter_default_2: "f64[s0, s0]" = torch.ops.aten.select_scatter.default(select_scatter_default_1, select_13, 1, 0);  select_scatter_default_1 = select_13 = None
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc, code: u[:, ny-1] = u[:, ny-2]
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_17: "f64[s0]" = torch.ops.aten.select.int(select_scatter_default_2, 1, 299)
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_18: "f64[s0]" = torch.ops.aten.select.int(select_scatter_default_2, 1, 298)
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # No stacktrace found for following nodes
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         select_scatter_default_3: "f64[s0, s0]" = torch.ops.aten.select_scatter.default(select_scatter_default_2, select_18, 1, 299);  select_scatter_default_2 = select_18 = None
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc, code: u[:, ny-1] = u[:, ny-2]
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         copy_: "f64[s0, s0]" = torch.ops.aten.copy_.default(arg1_1, select_scatter_default_3);  arg1_1 = select_scatter_default_3 = None
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         return (copy_,)
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs]         
V0227 18:03:09.955000 22563112417088 torch/_inductor/compile_fx.py:640] [0/0] [__post_grad_graphs] 
V0227 18:03:09.973000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %arg0_1 : [num_users=0] = placeholder[target=arg0_1] 
V0227 18:03:09.973000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %arg1_1 : [num_users=6] = placeholder[target=arg1_1] 
V0227 18:03:09.975000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %arg2_1 : [num_users=0] = placeholder[target=arg2_1] 
V0227 18:03:09.975000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %arg3_1 : [num_users=0] = placeholder[target=arg3_1] 
V0227 18:03:09.976000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %select_2 : [num_users=0] = call_function[target=torch.ops.aten.select.int](args = (%arg1_1, 0, 0), kwargs = {}) 
V0227 18:03:09.976000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x148498752200>
V0227 18:03:09.977000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval False == False [statically known]
V0227 18:03:09.978000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval True == True [statically known]
V0227 18:03:09.981000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %select_1 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%arg1_1, 0, 0), kwargs = {}) 
V0227 18:03:09.981000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x148498752200>
V0227 18:03:09.983000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %slice_2 : [num_users=0] = call_function[target=torch.ops.aten.slice.Tensor](args = (%select_1, 0, 1, 299), kwargs = {}) 
V0227 18:03:09.983000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function slice_ at 0x1484987514e0>
V0227 18:03:09.986000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval 299 < s0 + 1 == True [statically known]
V0227 18:03:09.987000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %select : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%arg1_1, 0, 1), kwargs = {}) 
V0227 18:03:09.987000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x148498752200>
V0227 18:03:09.990000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval 2 < s0 + 1 == True [statically known]
V0227 18:03:09.990000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %slice_1 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%select, 0, 1, 299), kwargs = {}) 
V0227 18:03:09.991000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function slice_ at 0x1484987514e0>
V0227 18:03:09.992000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %select_int : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%arg1_1, 0, 0), kwargs = {}) 
V0227 18:03:09.992000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x148498752200>
V0227 18:03:09.993000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %slice_scatter_default : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%select_int, %slice_1, 0, 1, 299), kwargs = {}) 
V0227 18:03:09.993000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function slice_scatter at 0x1484987d4e00>
V0227 18:03:09.998000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %select_scatter_default : [num_users=5] = call_function[target=torch.ops.aten.select_scatter.default](args = (%arg1_1, %slice_scatter_default, 0, 0), kwargs = {}) 
V0227 18:03:09.998000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function select_scatter at 0x1484987d4cc0>
V0227 18:03:10.005000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %select_8 : [num_users=0] = call_function[target=torch.ops.aten.select.int](args = (%select_scatter_default, 0, 299), kwargs = {}) 
V0227 18:03:10.005000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x148498752200>
I0227 18:03:10.050000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval 300 < s0 + 1 [guard added] (_inductor/ir.py:2320 in clamp)
V0227 18:03:10.052000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %select_6 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%select_scatter_default, 0, 299), kwargs = {}) 
V0227 18:03:10.053000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x148498752200>
V0227 18:03:10.056000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %slice_6 : [num_users=0] = call_function[target=torch.ops.aten.slice.Tensor](args = (%select_6, 0, 1, 299), kwargs = {}) 
V0227 18:03:10.056000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function slice_ at 0x1484987514e0>
V0227 18:03:10.059000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %select_7 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%select_scatter_default, 0, 298), kwargs = {}) 
V0227 18:03:10.059000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x148498752200>
V0227 18:03:10.066000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval 298 < s0 + 1 == True [statically known]
V0227 18:03:10.068000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %slice_7 : [num_users=1] = call_function[target=torch.ops.aten.slice.Tensor](args = (%select_7, 0, 1, 299), kwargs = {}) 
V0227 18:03:10.068000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function slice_ at 0x1484987514e0>
V0227 18:03:10.069000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %select_int_1 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%select_scatter_default, 0, 299), kwargs = {}) 
V0227 18:03:10.069000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x148498752200>
V0227 18:03:10.071000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %slice_scatter_default_1 : [num_users=1] = call_function[target=torch.ops.aten.slice_scatter.default](args = (%select_int_1, %slice_7, 0, 1, 299), kwargs = {}) 
V0227 18:03:10.071000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function slice_scatter at 0x1484987d4e00>
V0227 18:03:10.076000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %select_scatter_default_1 : [num_users=3] = call_function[target=torch.ops.aten.select_scatter.default](args = (%select_scatter_default, %slice_scatter_default_1, 0, 299), kwargs = {}) 
V0227 18:03:10.076000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function select_scatter at 0x1484987d4cc0>
I0227 18:03:10.096000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval 299 < s0 [guard added] (_inductor/lowering.py:2519 in select_scatter)
V0227 18:03:10.113000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %select_12 : [num_users=0] = call_function[target=torch.ops.aten.select.int](args = (%select_scatter_default_1, 1, 0), kwargs = {}) 
V0227 18:03:10.113000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x148498752200>
V0227 18:03:10.119000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %select_13 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%select_scatter_default_1, 1, 1), kwargs = {}) 
V0227 18:03:10.119000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x148498752200>
V0227 18:03:10.120000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %select_scatter_default_2 : [num_users=3] = call_function[target=torch.ops.aten.select_scatter.default](args = (%select_scatter_default_1, %select_13, 1, 0), kwargs = {}) 
V0227 18:03:10.120000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function select_scatter at 0x1484987d4cc0>
V0227 18:03:10.125000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %select_17 : [num_users=0] = call_function[target=torch.ops.aten.select.int](args = (%select_scatter_default_2, 1, 299), kwargs = {}) 
V0227 18:03:10.125000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x148498752200>
V0227 18:03:10.127000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %select_18 : [num_users=1] = call_function[target=torch.ops.aten.select.int](args = (%select_scatter_default_2, 1, 298), kwargs = {}) 
V0227 18:03:10.127000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function select at 0x148498752200>
V0227 18:03:10.129000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %select_scatter_default_3 : [num_users=1] = call_function[target=torch.ops.aten.select_scatter.default](args = (%select_scatter_default_2, %select_18, 1, 299), kwargs = {}) 
V0227 18:03:10.129000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function select_scatter at 0x1484987d4cc0>
V0227 18:03:10.132000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering %copy_ : [num_users=1] = call_function[target=torch.ops.aten.copy_.default](args = (%arg1_1, %select_scatter_default_3), kwargs = {}) 
V0227 18:03:10.132000 22563112417088 torch/_inductor/graph.py:815] [0/0]   via <function copy_ at 0x1484987f71a0>
V0227 18:03:10.142000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0**2 < 2 == False [statically known]
V0227 18:03:10.143000 22563112417088 torch/_inductor/graph.py:925] [0/0] lowering return (copy_,) 
V0227 18:03:10.148000 22563112417088 torch/_inductor/graph.py:904] [0/0] Force channels last inputs for 0 conv for the current graph with id 0
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0] scheduling ComputedBuffer(name='buf0', layout=FixedLayout('cuda', torch.float64, size=[s0, s0], stride=[s0, 1]), data=Pointwise(
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   'cuda',
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   torch.float64,
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   def inner_fn(index):
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       i0, i1 = index
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp0 = ops.index_expr(i0, torch.int32)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp1 = ops.index_expr(299, torch.int32)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp2 = tmp0 == tmp1
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp3 = ops.index_expr(i1, torch.int64)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp4 = ops.index_expr(1, torch.int64)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp5 = tmp3 >= tmp4
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp6 = ops.index_expr(299, torch.int64)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp7 = tmp3 < tmp6
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp8 = tmp5 & tmp7
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp9 = ops.index_expr(298, torch.int32)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp10 = ops.index_expr(0, torch.int32)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp11 = tmp9 == tmp10
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp12 = ops.index_expr(i1, torch.int64)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp13 = ops.index_expr(1, torch.int64)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp14 = tmp12 >= tmp13
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp15 = ops.index_expr(299, torch.int64)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp16 = tmp12 < tmp15
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp17 = tmp14 & tmp16
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp18 = ops.load(arg1_1, i1 + s0)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp19 = ops.masked(tmp17, tmp18, 0.0)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp20 = ops.load(arg1_1, i1)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp21 = ops.where(tmp17, tmp19, tmp20)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp22 = ops.load(arg1_1, i1 + 298 * s0)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp23 = ops.where(tmp11, tmp21, tmp22)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp24 = ops.masked(tmp8, tmp23, 0.0)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp25 = ops.index_expr(299, torch.int32)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp26 = ops.index_expr(0, torch.int32)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp27 = tmp25 == tmp26
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp28 = ops.index_expr(i1, torch.int64)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp29 = ops.index_expr(1, torch.int64)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp30 = tmp28 >= tmp29
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp31 = ops.index_expr(299, torch.int64)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp32 = tmp28 < tmp31
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp33 = tmp30 & tmp32
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp34 = ops.load(arg1_1, i1 + s0)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp35 = ops.masked(tmp33, tmp34, 0.0)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp36 = ops.load(arg1_1, i1)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp37 = ops.where(tmp33, tmp35, tmp36)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp38 = ops.load(arg1_1, i1 + 299 * s0)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp39 = ops.where(tmp27, tmp37, tmp38)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp40 = ops.where(tmp8, tmp24, tmp39)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp41 = ops.index_expr(i0, torch.int32)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp42 = ops.index_expr(0, torch.int32)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp43 = tmp41 == tmp42
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp44 = ops.index_expr(i1, torch.int64)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp45 = ops.index_expr(1, torch.int64)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp46 = tmp44 >= tmp45
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp47 = ops.index_expr(299, torch.int64)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp48 = tmp44 < tmp47
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp49 = tmp46 & tmp48
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp50 = ops.load(arg1_1, i1 + s0)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp51 = ops.masked(tmp49, tmp50, 0.0)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp52 = ops.load(arg1_1, i1)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp53 = ops.where(tmp49, tmp51, tmp52)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp54 = ops.load(arg1_1, i1 + i0 * s0)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp55 = ops.where(tmp43, tmp53, tmp54)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp56 = ops.where(tmp2, tmp40, tmp55)
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       return tmp56
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   ,
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   ranges=[s0, s0],
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   origin_node=select_scatter_default_1,
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   origins={slice_scatter_default, select_scatter_default_1, sli...
V0227 18:03:10.264000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0] ))
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0] scheduling ComputedBuffer(name='buf1', layout=FixedLayout('cuda', torch.float64, size=[s0], stride=[1]), data=Pointwise(
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   'cuda',
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   torch.float64,
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   def inner_fn(index):
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       i0 = index
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp0 = ops.index_expr(i0, torch.int64)
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp1 = ops.index_expr(1, torch.int64)
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp2 = tmp0 >= tmp1
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp3 = ops.index_expr(299, torch.int64)
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp4 = tmp0 < tmp3
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp5 = tmp2 & tmp4
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp6 = ops.load(arg1_1, i0 + s0)
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp7 = ops.masked(tmp5, tmp6, 0.0)
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp8 = ops.load(arg1_1, i0)
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp9 = ops.where(tmp5, tmp7, tmp8)
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       return tmp9
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   ,
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   ranges=[s0],
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   origin_node=slice_scatter_default,
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   origins={slice_scatter_default}
V0227 18:03:10.268000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0] ))
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0] scheduling ComputedBuffer(name='buf2', layout=FixedLayout('cuda', torch.float64, size=[s0, s0], stride=[s0, 1]), data=Pointwise(
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   'cuda',
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   torch.float64,
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   def inner_fn(index):
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       i0, i1 = index
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp0 = ops.index_expr(i0, torch.int32)
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp1 = ops.index_expr(0, torch.int32)
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp2 = tmp0 == tmp1
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp3 = ops.index_expr(i1, torch.int64)
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp4 = ops.index_expr(1, torch.int64)
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp5 = tmp3 >= tmp4
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp6 = ops.index_expr(299, torch.int64)
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp7 = tmp3 < tmp6
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp8 = tmp5 & tmp7
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp9 = ops.load(arg1_1, i1 + s0)
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp10 = ops.masked(tmp8, tmp9, 0.0)
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp11 = ops.load(arg1_1, i1)
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp12 = ops.where(tmp8, tmp10, tmp11)
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp13 = ops.load(arg1_1, i1 + i0 * s0)
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp14 = ops.where(tmp2, tmp12, tmp13)
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       return tmp14
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   ,
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   ranges=[s0, s0],
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   origin_node=select_scatter_default,
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   origins={slice_scatter_default, select_scatter_default}
V0227 18:03:10.269000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0] ))
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0] scheduling ComputedBuffer(name='buf3', layout=FixedLayout('cuda', torch.float64, size=[s0], stride=[1]), data=Pointwise(
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   'cuda',
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   torch.float64,
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   def inner_fn(index):
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       i0 = index
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp0 = ops.index_expr(i0, torch.int64)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp1 = ops.index_expr(1, torch.int64)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp2 = tmp0 >= tmp1
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp3 = ops.index_expr(299, torch.int64)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp4 = tmp0 < tmp3
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp5 = tmp2 & tmp4
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp6 = ops.index_expr(298, torch.int32)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp7 = ops.index_expr(0, torch.int32)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp8 = tmp6 == tmp7
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp9 = ops.index_expr(i0, torch.int64)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp10 = ops.index_expr(1, torch.int64)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp11 = tmp9 >= tmp10
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp12 = ops.index_expr(299, torch.int64)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp13 = tmp9 < tmp12
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp14 = tmp11 & tmp13
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp15 = ops.load(arg1_1, i0 + s0)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp16 = ops.masked(tmp14, tmp15, 0.0)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp17 = ops.load(arg1_1, i0)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp18 = ops.where(tmp14, tmp16, tmp17)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp19 = ops.load(arg1_1, i0 + 298 * s0)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp20 = ops.where(tmp8, tmp18, tmp19)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp21 = ops.masked(tmp5, tmp20, 0.0)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp22 = ops.index_expr(299, torch.int32)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp23 = ops.index_expr(0, torch.int32)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp24 = tmp22 == tmp23
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp25 = ops.index_expr(i0, torch.int64)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp26 = ops.index_expr(1, torch.int64)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp27 = tmp25 >= tmp26
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp28 = ops.index_expr(299, torch.int64)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp29 = tmp25 < tmp28
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp30 = tmp27 & tmp29
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp31 = ops.load(arg1_1, i0 + s0)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp32 = ops.masked(tmp30, tmp31, 0.0)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp33 = ops.load(arg1_1, i0)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp34 = ops.where(tmp30, tmp32, tmp33)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp35 = ops.load(arg1_1, i0 + 299 * s0)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp36 = ops.where(tmp24, tmp34, tmp35)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp37 = ops.where(tmp5, tmp21, tmp36)
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       return tmp37
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   ,
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   ranges=[s0],
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   origin_node=slice_scatter_default_1,
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   origins={slice_scatter_default_1}
V0227 18:03:10.271000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0] ))
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0] scheduling ComputedBuffer(name='buf4', layout=FixedLayout('cuda', torch.float64, size=[s0, s0], stride=[s0, 1]), data=Pointwise(
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   'cuda',
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   torch.float64,
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   def inner_fn(index):
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       i0, i1 = index
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp0 = ops.index_expr(i1, torch.int32)
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp1 = ops.index_expr(299, torch.int32)
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp2 = tmp0 == tmp1
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp3 = ops.index_expr(298, torch.int32)
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp4 = ops.index_expr(0, torch.int32)
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp5 = tmp3 == tmp4
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp6 = ops.load(buf0, 1 + i0 * s0)
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp7 = ops.load(buf0, 298 + i0 * s0)
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp8 = ops.where(tmp5, tmp6, tmp7)
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp9 = ops.index_expr(i1, torch.int32)
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp10 = ops.index_expr(0, torch.int32)
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp11 = tmp9 == tmp10
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp12 = ops.load(buf0, 1 + i0 * s0)
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp13 = ops.load(buf0, i1 + i0 * s0)
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp14 = ops.where(tmp11, tmp12, tmp13)
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp15 = ops.where(tmp2, tmp8, tmp14)
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       return tmp15
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   ,
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   ranges=[s0, s0],
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   origin_node=select_scatter_default_3,
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   origins={select_scatter_default_3, select_scatter_default_2}
V0227 18:03:10.273000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0] ))
V0227 18:03:10.275000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0] scheduling ComputedBuffer(name='buf5', layout=MutationLayout('cuda', torch.float64, size=[s0, s0], stride=[s0, 1]), data=Pointwise(
V0227 18:03:10.275000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   'cuda',
V0227 18:03:10.275000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   torch.float64,
V0227 18:03:10.275000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   def inner_fn(index):
V0227 18:03:10.275000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       i0, i1 = index
V0227 18:03:10.275000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       tmp0 = ops.load(buf4, i1 + i0 * s0)
V0227 18:03:10.275000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]       return tmp0
V0227 18:03:10.275000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   ,
V0227 18:03:10.275000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   ranges=[s0, s0],
V0227 18:03:10.275000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   origin_node=None,
V0227 18:03:10.275000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0]   origins={select_scatter_default_3, copy_, select_scatter_defa...
V0227 18:03:10.275000 22563112417088 torch/_inductor/scheduler.py:1480] [0/0] ))
V0227 18:03:10.276000 22563112417088 torch/_inductor/scheduler.py:1539] [0/0] scheduling output arg1_1
V0227 18:03:10.276000 22563112417088 torch/_inductor/scheduler.py:1627] [0/0] removed dead node: buf1
V0227 18:03:10.276000 22563112417088 torch/_inductor/scheduler.py:1627] [0/0] removed dead node: buf2
V0227 18:03:10.276000 22563112417088 torch/_inductor/scheduler.py:1627] [0/0] removed dead node: buf3
I0227 18:03:10.285000 22563112417088 torch/_inductor/debug.py:469] [0/0] Writing debug ir to  /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/torch_compile_debug/run_2025_02_27_18_03_00_154903-pid_474543/torchinductor/model___9.0/ir_pre_fusion.txt
I0227 18:03:10.334000 22563112417088 torch/_inductor/debug.py:469] [0/0] Writing debug ir to  /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/torch_compile_debug/run_2025_02_27_18_03_00_154903-pid_474543/torchinductor/model___9.0/ir_post_fusion.txt
V0227 18:03:10.376000 22563112417088 torch/_inductor/scheduler.py:2298] [0/0] Generating code for node buf0 with estimated runtime 0.000000
I0227 18:03:10.471000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s0**2 < 2147483648 [guard added] (_inductor/codegen/triton.py:3300 in can_use_32bit_indexing)
I0227 18:03:10.486000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s0*(s0 - 1) + s0 < 2147483648 [guard added] (_inductor/codegen/triton.py:3302 in can_use_32bit_indexing)
V0227 18:03:14.310000 22563112417088 torch/_inductor/codegen/triton.py:3428] [0/0] Generating kernel code with kernel_name: triton_poi_fused_0
V0227 18:03:14.310000 22563112417088 torch/_inductor/scheduler.py:2298] [0/0] Generating code for node buf4_buf5 with estimated runtime 0.000000
V0227 18:03:14.325000 22563112417088 torch/_inductor/scheduler.py:2220] [0/0] remove_buffer('buf4')
V0227 18:03:14.326000 22563112417088 torch/_inductor/codegen/triton.py:3428] [0/0] Generating kernel code with kernel_name: triton_poi_fused_1
V0227 18:03:14.669000 22563112417088 torch/_inductor/triton_heuristics.py:170] [0/0] CachingAutotuner gets 1 configs for triton_
V0227 18:03:14.669000 22563112417088 torch/_inductor/triton_heuristics.py:176] [0/0] XBLOCK: 512, num_warps: 8, num_ctas: 1, num_stages: 1, enable_warp_specialization: False, enable_persistent: False
V0227 18:03:14.800000 22563112417088 torch/_inductor/triton_heuristics.py:170] [0/0] CachingAutotuner gets 1 configs for triton_
V0227 18:03:14.800000 22563112417088 torch/_inductor/triton_heuristics.py:176] [0/0] XBLOCK: 512, num_warps: 8, num_ctas: 1, num_stages: 1, enable_warp_specialization: False, enable_persistent: False
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1266] [0/0] Output code written to: /scratch/tmp.24755961.konradha/torchinductor_konradha/x5/cx5yjpum273nhwdrktkdsaw5jh7zzs66ixnigthl4j5xe5skn5iz.py
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] Output code: 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from ctypes import c_void_p, c_long
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] import torch
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] import math
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] import random
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] import os
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] import tempfile
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from math import inf, nan
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.hooks import run_intermediate_hooks
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.utils import maybe_profile
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.codegen.memory_planning import _align as align
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch import device, empty_strided
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.codecache import AsyncCompile
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.select_algorithm import extern_kernels
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.codegen.multi_kernel import MultiKernelCall
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] aten = torch.ops.aten
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] inductor_ops = torch.ops.inductor
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] assert_size_stride = torch._C._dynamo.guards.assert_size_stride
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] empty_strided_cpu = torch._C._dynamo.guards._empty_strided_cpu
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] empty_strided_cuda = torch._C._dynamo.guards._empty_strided_cuda
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] alloc_from_pool = torch.ops.inductor._alloc_from_pool
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] reinterpret_tensor = torch.ops.inductor._reinterpret_tensor
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] async_compile = AsyncCompile()
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] # kernel path: /scratch/tmp.24755961.konradha/torchinductor_konradha/rq/crq3m3grnclfckvkksxrf2jg73hagwieolxo3rlgu2z2v663afl3.py
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] # Source Nodes: [], Original ATen: []
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] triton_poi_fused_0 = async_compile.triton('triton_', '''
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] import triton
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] import triton.language as tl
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor import triton_helpers, triton_heuristics
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.ir import ReductionHint, TileHint
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.triton_helpers import libdevice, math as tl_math
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.triton_heuristics import AutotuneHint
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.utils import instance_descriptor
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] @triton_heuristics.pointwise(
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     size_hints=[131072], 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     filename=__file__,
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     triton_meta={'signature': {0: '*fp64', 1: '*fp64', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]},
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_0', 'mutated_arg_names': [], 'no_x_dim': False, 'backend_hash': '3c9eac74f04023b38fe37317f0afe4f78f5f0ccf49418abd41d59a08f8a919b2'},
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     min_elem_per_thread=0
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] )
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] @triton.jit
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] def triton_(in_ptr0, out_ptr0, ks0, xnumel, XBLOCK : tl.constexpr):
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     xmask = xindex < xnumel
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     x1 = (xindex // ks0)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     x0 = xindex % ks0
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     x2 = xindex
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp26 = tl.load(in_ptr0 + (x0), xmask, eviction_policy='evict_last')
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp28 = tl.load(in_ptr0 + (x0 + (299*ks0)), xmask, eviction_policy='evict_last')
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp32 = tl.load(in_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp0 = x1
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp1 = tl.full([1], 299, tl.int32)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp2 = tmp0 == tmp1
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp3 = x0
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp4 = tl.full([1], 1, tl.int64)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp5 = tmp3 >= tmp4
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp6 = tl.full([1], 299, tl.int64)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp7 = tmp3 < tmp6
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp8 = tmp5 & tmp7
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp9 = tl.full([1], 298, tl.int32)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp10 = tl.full([1], 0, tl.int32)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp11 = tmp9 == tmp10
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp12 = tmp8 & tmp8
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp13 = tl.load(in_ptr0 + (ks0 + x0), tmp12 & xmask, eviction_policy='evict_last', other=0.0)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp14 = tl.full(tmp13.shape, 0.0, tmp13.dtype)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp15 = tl.where(tmp12, tmp13, tmp14)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp16 = tl.load(in_ptr0 + (x0), tmp8 & xmask, eviction_policy='evict_last', other=0.0)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp17 = tl.where(tmp8, tmp15, tmp16)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp18 = tl.load(in_ptr0 + (x0 + (298*ks0)), tmp8 & xmask, eviction_policy='evict_last', other=0.0)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp19 = tl.where(tmp11, tmp17, tmp18)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp20 = tl.full(tmp19.shape, 0.0, tmp19.dtype)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp21 = tl.where(tmp8, tmp19, tmp20)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp22 = tmp1 == tmp10
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp23 = tl.load(in_ptr0 + (ks0 + x0), tmp8 & xmask, eviction_policy='evict_last', other=0.0)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp24 = tl.full(tmp23.shape, 0.0, tmp23.dtype)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp25 = tl.where(tmp8, tmp23, tmp24)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp27 = tl.where(tmp8, tmp25, tmp26)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp29 = tl.where(tmp22, tmp27, tmp28)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp30 = tl.where(tmp8, tmp21, tmp29)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp31 = tmp0 == tmp10
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp33 = tl.where(tmp31, tmp27, tmp32)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp34 = tl.where(tmp2, tmp30, tmp33)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tl.store(out_ptr0 + (x2), tmp34, xmask)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] ''', device_str='cuda')
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] import triton
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] import triton.language as tl
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.triton_heuristics import grid, split_scan_grid, start_graph, end_graph
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._C import _cuda_getCurrentRawStream as get_raw_stream
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] # kernel path: /scratch/tmp.24755961.konradha/torchinductor_konradha/uv/cuvi747mgngom33pwxvrie4po5isymwvermlnz5tybblus7yhtl5.py
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] # Source Nodes: [], Original ATen: []
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] triton_poi_fused_1 = async_compile.triton('triton_', '''
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] import triton
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] import triton.language as tl
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from triton.compiler.compiler import AttrsDescriptor
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor import triton_helpers, triton_heuristics
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.ir import ReductionHint, TileHint
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.triton_helpers import libdevice, math as tl_math
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.triton_heuristics import AutotuneHint
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] from torch._inductor.utils import instance_descriptor
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] @triton_heuristics.pointwise(
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     size_hints=[131072], 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     filename=__file__,
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     triton_meta={'signature': {0: '*fp64', 1: '*fp64', 2: 'i32', 3: 'i32'}, 'device': 0, 'device_type': 'cuda', 'constants': {}, 'configs': [AttrsDescriptor(divisible_by_16=(0, 1), equal_to_1=(), ids_of_folded_args=(), divisible_by_8=())]},
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     inductor_meta={'autotune_hints': set(), 'kernel_name': 'triton_poi_fused_1', 'mutated_arg_names': ['out_ptr1'], 'no_x_dim': False, 'backend_hash': '3c9eac74f04023b38fe37317f0afe4f78f5f0ccf49418abd41d59a08f8a919b2'},
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     min_elem_per_thread=0
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] )
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] @triton.jit
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] def triton_(in_ptr0, out_ptr1, ks0, xnumel, XBLOCK : tl.constexpr):
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     xoffset = tl.program_id(0) * XBLOCK
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     xindex = xoffset + tl.arange(0, XBLOCK)[:]
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     xmask = xindex < xnumel
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     x0 = xindex % ks0
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     x1 = (xindex // ks0)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     x2 = xindex
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp6 = tl.load(in_ptr0 + (1 + (ks0*x1)), xmask, eviction_policy='evict_last')
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp7 = tl.load(in_ptr0 + (298 + (ks0*x1)), xmask, eviction_policy='evict_last')
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp10 = tl.load(in_ptr0 + (x2), xmask, eviction_policy='evict_last')
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp0 = x0
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp1 = tl.full([1], 299, tl.int32)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp2 = tmp0 == tmp1
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp3 = tl.full([1], 298, tl.int32)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp4 = tl.full([1], 0, tl.int32)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp5 = tmp3 == tmp4
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp8 = tl.where(tmp5, tmp6, tmp7)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp9 = tmp0 == tmp4
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp11 = tl.where(tmp9, tmp6, tmp10)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tmp12 = tl.where(tmp2, tmp8, tmp11)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     tl.store(out_ptr1 + (x2), tmp12, xmask)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] ''', device_str='cuda')
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] async_compile.wait(globals())
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] del async_compile
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] def call(args):
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     arg0_1, arg1_1, arg2_1, arg3_1 = args
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     args.clear()
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     s0 = arg0_1
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     for kernel in globals().values():
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]         if isinstance(kernel, torch._inductor.triton_heuristics.CachingAutotuner):
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]             kernel.cuda_kernel_saved = False
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     with torch.cuda._DeviceGuard(0):
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]         torch.cuda.set_device(0)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]         buf0 = empty_strided_cuda((s0, s0), (s0, 1), torch.float64)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]         # Source Nodes: [], Original ATen: []
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]         triton_poi_fused_0_xnumel = s0*s0
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]         stream0 = get_raw_stream(0)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]         triton_poi_fused_0.run(arg1_1, buf0, s0, triton_poi_fused_0_xnumel, grid=grid(triton_poi_fused_0_xnumel), stream=stream0)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]         torch.cuda.synchronize()
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]         # Source Nodes: [], Original ATen: []
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]         triton_poi_fused_1_xnumel = s0*s0
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]         triton_poi_fused_1.run(buf0, arg1_1, s0, triton_poi_fused_1_xnumel, grid=grid(triton_poi_fused_1_xnumel), stream=stream0)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]         del buf0
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]         torch.cuda.synchronize()
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     for kernel in globals().values():
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]         if isinstance(kernel, torch._inductor.triton_heuristics.CachingAutotuner):
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]             if not kernel.cuda_kernel_saved:
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]                 if len(kernel.launchers) == 0:
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]                     kernel.precompile()
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]                 kernel.save_cuda_kernel(
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]                     grid=(0, 0, 0),   # use dummy grid
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]                     stream="stream",  # use dummy stream
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]                     launcher=kernel.launchers[0],
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]                 )
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     return (arg1_1, )
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] def benchmark_compiled_module(times=10, repeat=10):
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     from torch._dynamo.testing import rand_strided
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     from torch._inductor.utils import print_performance
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     arg0_1 = 300
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     arg1_1 = rand_strided((300, 300), (300, 1), device='cuda:0', dtype=torch.float64)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     arg2_1 = 300
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     arg3_1 = 300
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     fn = lambda: call([arg0_1, arg1_1, arg2_1, arg3_1])
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     return print_performance(fn, times=times, repeat=repeat)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] if __name__ == "__main__":
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     from torch._inductor.wrapper_benchmark import compiled_module_main
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code]     compiled_module_main('None', benchmark_compiled_module)
V0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1267] [0/0] [__output_code] 
I0227 18:03:14.910000 22563112417088 torch/_inductor/graph.py:1273] [0/0] [__output_code] Output code written to: /scratch/tmp.24755961.konradha/torchinductor_konradha/x5/cx5yjpum273nhwdrktkdsaw5jh7zzs66ixnigthl4j5xe5skn5iz.py
V0227 18:03:14.986000 22563112417088 torch/_inductor/compile_fx.py:442] [0/0] FX codegen and compilation took 5.316s
I0227 18:03:14.987000 22563112417088 torch/_dynamo/logging.py:55] [0/0] Step 3: torchinductor done compiling FORWARDS graph 0
W0227 18:03:14.987000 22563112417088 torch/_inductor/debug.py:413] [0/0] model___9 debug trace: /scratch/tmp.24755961.konradha/torchinductor_konradha/x5/cx5yjpum273nhwdrktkdsaw5jh7zzs66ixnigthl4j5xe5skn5iz.debug
I0227 18:03:14.994000 22563112417088 torch/_dynamo/logging.py:55] [0/0] Step 2: done compiler function inductor
I0227 18:03:15.009000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2806] [0/0] produce_guards
V0227 18:03:15.009000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].size()[0] s0 None
V0227 18:03:15.010000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].size()[1] s0 None
V0227 18:03:15.010000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].stride()[0] s0 None
V0227 18:03:15.010000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].stride()[1] 1 None
V0227 18:03:15.010000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].storage_offset() 0 None
V0227 18:03:15.011000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['ny'] 300 None
V0227 18:03:15.011000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['nx'] 300 None
V0227 18:03:15.011000 22563112417088 torch/fx/experimental/symbolic_shapes.py:3138] [0/0] Skipping guard L['u'].stride()[1] == 1
V0227 18:03:15.012000 22563112417088 torch/fx/experimental/symbolic_shapes.py:3138] [0/0] Skipping guard L['u'].storage_offset() == 0
V0227 18:03:15.028000 22563112417088 torch/_dynamo/guards.py:1076] [0/0] [__guards] GUARDS:
V0227 18:03:15.028000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] ___check_type_id(L['u'], 86261344)                            # assert len(u.shape) == 2  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc
V0227 18:03:15.040000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] hasattr(L['u'], '_dynamo_dynamic_indices') == False           # assert len(u.shape) == 2  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc
V0227 18:03:15.047000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] ___check_type_id(L['nx'], 22563121958112)                     # u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc
V0227 18:03:15.048000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] ___check_type_id(L['ny'], 22563121958112)                     # u[0, 1:ny-1]    = u[1, 1:ny-1]  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc
V0227 18:03:15.049000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:430 in init_ambient_guards
V0227 18:03:15.049000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] ___check_current_backend(22560042014928)                      # _dynamo/output_graph.py:436 in init_ambient_guards
V0227 18:03:15.050000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] check_tensor(L['u'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float64, device=0, requires_grad=False, size=[None, None], stride=[None, 1])  # assert len(u.shape) == 2  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc
V0227 18:03:15.051000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['u'].size()[1] == L['u'].size()[0]                          # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.052000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['u'].stride()[0] == L['u'].size()[0]                        # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.052000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['ny'] == 300                                                # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.053000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['nx'] == 300                                                # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.054000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['u'].size()[0] > 299                                        # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.054000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] 300 < L['u'].size()[0] + 1                                    # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.055000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] 299 < L['u'].size()[0]                                        # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.055000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['u'].size()[0]**2 < 2147483648                              # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.055000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] 299 <= L['u'].size()[0]                                       # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.056000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['u'].stride()[0] == L['u'].size()[0]                        # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.056000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['ny'] == 300                                                # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.056000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['nx'] == 300                                                # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.056000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['u'].size()[0] > 299                                        # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.057000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] 300 < L['u'].size()[0] + 1                                    # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.057000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] 299 < L['u'].size()[0]                                        # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.057000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['u'].size()[0]**2 < 2147483648                              # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.058000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] 299 <= L['u'].size()[0]                                       # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.066000 22563112417088 torch/_dynamo/convert_frame.py:652] [0/0] torchdynamo start compiling neumann_bc /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:18, stack (elided 5 frames):
V0227 18:03:15.066000 22563112417088 torch/_dynamo/convert_frame.py:652] [0/0]   File "/cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py", line 59, in <module>
V0227 18:03:15.066000 22563112417088 torch/_dynamo/convert_frame.py:652] [0/0]     explanation = dynamo.explain(compiled_fn)(test_tensor, nx, ny)
V0227 18:03:15.066000 22563112417088 torch/_dynamo/convert_frame.py:652] [0/0]   File "/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 728, in inner
V0227 18:03:15.066000 22563112417088 torch/_dynamo/convert_frame.py:652] [0/0]     opt_f(*args, **kwargs)
V0227 18:03:15.066000 22563112417088 torch/_dynamo/convert_frame.py:652] [0/0]   File "/cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/_dynamo/eval_frame.py", line 451, in _fn
V0227 18:03:15.066000 22563112417088 torch/_dynamo/convert_frame.py:652] [0/0]     return fn(*args, **kwargs)
V0227 18:03:15.066000 22563112417088 torch/_dynamo/convert_frame.py:652] [0/0] 
I0227 18:03:15.081000 22563112417088 torch/_dynamo/logging.py:55] [0/0] Step 1: torchdynamo start tracing neumann_bc /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:18
V0227 18:03:15.081000 22563112417088 torch/fx/experimental/symbolic_shapes.py:1980] [0/0] create_env
V0227 18:03:15.082000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:18 in neumann_bc (neumann_bc)
V0227 18:03:15.082000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]     def neumann_bc(u: torch.Tensor, nx: int, ny: int) -> torch.Tensor:
V0227 18:03:15.083000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE RESUME 0 []
V0227 18:03:15.083000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc (neumann_bc)
V0227 18:03:15.083000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         assert len(u.shape) == 2
V0227 18:03:15.083000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_GLOBAL len []
V0227 18:03:15.084000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [NullVariable(), BuiltinVariable()]
V0227 18:03:15.084000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_ATTR shape [NullVariable(), BuiltinVariable(), LazyVariableTracker()]
V0227 18:03:15.085000 22563112417088 torch/_dynamo/output_graph.py:1959] [0/0] create_graph_input L_u_ L['u']
V0227 18:03:15.086000 22563112417088 torch/_dynamo/variables/builder.py:1873] [0/0] wrap_to_fake L['u'] (300, 300) StatefulSymbolicContext(dynamic_sizes=[<DimDynamic.DYNAMIC: 0>, <DimDynamic.DYNAMIC: 0>], constraint_sizes=[None, None], view_base_context=None, tensor_source=LocalSource(local_name='u', cell_or_freevar=False), shape_env_to_source_to_symbol_cache={}) <class 'torch.Tensor'>
I0227 18:03:15.087000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2724] [0/0] create_symbol s0 = 300 for L['u'].size()[0] [2, 9223372036854775806] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc (_dynamo/variables/builder.py:1881 in <lambda>)
I0227 18:03:15.091000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2724] [0/0] create_symbol s1 = 300 for L['u'].size()[1] [2, 9223372036854775806] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc (_dynamo/variables/builder.py:1881 in <lambda>)
V0227 18:03:15.092000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval True == True [statically known]
V0227 18:03:15.092000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval False == False [statically known]
V0227 18:03:15.096000 22563112417088 torch/_dynamo/output_graph.py:658] [0/0] bind_symint s0 L['u'].size()[0]
V0227 18:03:15.096000 22563112417088 torch/_dynamo/output_graph.py:1959] [0/0] create_graph_input s0 L['u'].size()[0]
V0227 18:03:15.097000 22563112417088 torch/_dynamo/output_graph.py:658] [0/0] bind_symint s1 L['u'].size()[1]
V0227 18:03:15.097000 22563112417088 torch/_dynamo/output_graph.py:1959] [0/0] create_graph_input s1 L['u'].size()[1]
V0227 18:03:15.097000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call size from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc (neumann_bc)
V0227 18:03:15.097000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     assert len(u.shape) == 2
V0227 18:03:15.097000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                ^^^^^^^
V0227 18:03:15.098000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE PRECALL 1 [NullVariable(), BuiltinVariable(), SizeVariable()]
V0227 18:03:15.098000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE CALL 1 [NullVariable(), BuiltinVariable(), SizeVariable()]
V0227 18:03:15.098000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 2 [ConstantVariable()]
V0227 18:03:15.098000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE COMPARE_OP == [ConstantVariable(), ConstantVariable()]
V0227 18:03:15.099000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE POP_JUMP_FORWARD_IF_TRUE 54 [ConstantVariable()]
V0227 18:03:15.099000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (neumann_bc)
V0227 18:03:15.099000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:03:15.099000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:03:15.099000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker()]
V0227 18:03:15.099000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), ConstantVariable()]
V0227 18:03:15.099000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:03:15.099000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker()]
V0227 18:03:15.099000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:15.100000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), ConstantVariable()]
V0227 18:03:15.100000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [LazyVariableTracker(), ConstantVariable(), SliceVariable()]
V0227 18:03:15.100000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_SUBSCR None [LazyVariableTracker(), TupleVariable()]
V0227 18:03:15.100000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call getitem_2 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (neumann_bc)
V0227 18:03:15.100000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:03:15.100000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                       ~^^^^^^^^^^^
V0227 18:03:15.102000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 > 1 == True [statically known]
V0227 18:03:15.103000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval False == False [statically known]
V0227 18:03:15.103000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 <= 1 == False [statically known]
I0227 18:03:15.107000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s1 >= 299 [guard added] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (_decomp/decompositions.py:756 in slice_forward)
V0227 18:03:15.108000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [TensorVariable()]
V0227 18:03:15.108000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 0 [TensorVariable(), LazyVariableTracker()]
V0227 18:03:15.108000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:15.109000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:03:15.109000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker()]
V0227 18:03:15.109000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:15.109000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), ConstantVariable()]
V0227 18:03:15.109000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), SliceVariable()]
V0227 18:03:15.109000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE STORE_SUBSCR None [TensorVariable(), LazyVariableTracker(), TupleVariable()]
V0227 18:03:15.109000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call setitem from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc (neumann_bc)
V0227 18:03:15.109000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:03:15.109000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     ~^^^^^^^^^^^
V0227 18:03:15.110000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:03:15.110000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:03:15.110000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:03:15.110000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST nx [LazyVariableTracker()]
V0227 18:03:15.110000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 2 [LazyVariableTracker(), LazyVariableTracker()]
V0227 18:03:15.110000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [LazyVariableTracker(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:15.110000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), ConstantVariable()]
V0227 18:03:15.111000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:03:15.111000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker()]
V0227 18:03:15.111000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:15.111000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [LazyVariableTracker(), ConstantVariable(), ConstantVariable(), ConstantVariable()]
V0227 18:03:15.111000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [LazyVariableTracker(), ConstantVariable(), SliceVariable()]
V0227 18:03:15.111000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_SUBSCR None [LazyVariableTracker(), TupleVariable()]
V0227 18:03:15.111000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call getitem_3 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:03:15.111000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:03:15.111000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                       ~^^^^^^^^^^^^^^
I0227 18:03:15.115000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4035] [0/0] eval s0 > 298 [guard added] at home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (_dynamo/utils.py:1764 in run_node)
V0227 18:03:15.116000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 <= 298 == False [statically known]
V0227 18:03:15.117000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [TensorVariable()]
V0227 18:03:15.117000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST nx [TensorVariable(), LazyVariableTracker()]
V0227 18:03:15.118000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), LazyVariableTracker()]
V0227 18:03:15.118000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [TensorVariable(), LazyVariableTracker(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:15.118000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:15.118000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:03:15.118000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker()]
V0227 18:03:15.118000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:15.118000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable(), ConstantVariable()]
V0227 18:03:15.119000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), SliceVariable()]
V0227 18:03:15.119000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE STORE_SUBSCR None [TensorVariable(), LazyVariableTracker(), TupleVariable()]
V0227 18:03:15.119000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call setitem_1 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc (neumann_bc)
V0227 18:03:15.119000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:03:15.119000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     ~^^^^^^^^^^^^^^
V0227 18:03:15.119000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc (neumann_bc)
V0227 18:03:15.119000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         u[:, 0]    = u[:, 1]
V0227 18:03:15.119000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:03:15.119000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [LazyVariableTracker()]
V0227 18:03:15.119000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [LazyVariableTracker(), ConstantVariable()]
V0227 18:03:15.120000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:03:15.120000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [LazyVariableTracker(), SliceVariable()]
V0227 18:03:15.120000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [LazyVariableTracker(), SliceVariable(), ConstantVariable()]
V0227 18:03:15.120000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_SUBSCR None [LazyVariableTracker(), TupleVariable()]
V0227 18:03:15.120000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call getitem_4 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc (neumann_bc)
V0227 18:03:15.120000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, 0]    = u[:, 1]
V0227 18:03:15.120000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                  ~^^^^^^
V0227 18:03:15.125000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval Eq(s0, 9223372036854775807) == False [statically known]
V0227 18:03:15.127000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s0 < 9223372036854775807 == True [statically known]
V0227 18:03:15.130000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s1 > 1 == True [statically known]
V0227 18:03:15.131000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s1 <= 1 == False [statically known]
V0227 18:03:15.132000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [TensorVariable()]
V0227 18:03:15.132000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [TensorVariable(), LazyVariableTracker()]
V0227 18:03:15.132000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [TensorVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:15.132000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:03:15.132000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 0 [TensorVariable(), LazyVariableTracker(), SliceVariable()]
V0227 18:03:15.132000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [TensorVariable(), LazyVariableTracker(), SliceVariable(), ConstantVariable()]
V0227 18:03:15.132000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE STORE_SUBSCR None [TensorVariable(), LazyVariableTracker(), TupleVariable()]
V0227 18:03:15.132000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call setitem_2 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc (neumann_bc)
V0227 18:03:15.132000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, 0]    = u[:, 1]
V0227 18:03:15.132000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     ~^^^^^^
V0227 18:03:15.133000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (neumann_bc)
V0227 18:03:15.133000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         u[:, ny-1] = u[:, ny-2]
V0227 18:03:15.133000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:03:15.133000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [LazyVariableTracker()]
V0227 18:03:15.133000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [LazyVariableTracker(), ConstantVariable()]
V0227 18:03:15.133000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:03:15.133000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [LazyVariableTracker(), SliceVariable()]
V0227 18:03:15.133000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 2 [LazyVariableTracker(), SliceVariable(), LazyVariableTracker()]
V0227 18:03:15.134000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [LazyVariableTracker(), SliceVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:15.134000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [LazyVariableTracker(), SliceVariable(), ConstantVariable()]
V0227 18:03:15.134000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_SUBSCR None [LazyVariableTracker(), TupleVariable()]
V0227 18:03:15.134000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call getitem_5 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (neumann_bc)
V0227 18:03:15.134000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, ny-1] = u[:, ny-2]
V0227 18:03:15.134000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]                  ~^^^^^^^^^
V0227 18:03:15.138000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s1 > 298 == True [statically known]
V0227 18:03:15.139000 22563112417088 torch/fx/experimental/symbolic_shapes.py:4119] [0/0] eval s1 <= 298 == False [statically known]
V0227 18:03:15.140000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u [TensorVariable()]
V0227 18:03:15.140000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [TensorVariable(), LazyVariableTracker()]
V0227 18:03:15.140000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST None [TensorVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:15.140000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_SLICE 2 [TensorVariable(), LazyVariableTracker(), ConstantVariable(), ConstantVariable()]
V0227 18:03:15.140000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST ny [TensorVariable(), LazyVariableTracker(), SliceVariable()]
V0227 18:03:15.140000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_CONST 1 [TensorVariable(), LazyVariableTracker(), SliceVariable(), LazyVariableTracker()]
V0227 18:03:15.140000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BINARY_OP 10 [TensorVariable(), LazyVariableTracker(), SliceVariable(), LazyVariableTracker(), ConstantVariable()]
V0227 18:03:15.141000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE BUILD_TUPLE 2 [TensorVariable(), LazyVariableTracker(), SliceVariable(), ConstantVariable()]
V0227 18:03:15.141000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE STORE_SUBSCR None [TensorVariable(), LazyVariableTracker(), TupleVariable()]
V0227 18:03:15.141000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call] TRACE FX call setitem_3 from /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc (neumann_bc)
V0227 18:03:15.141000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     u[:, ny-1] = u[:, ny-2]
V0227 18:03:15.141000 22563112417088 torch/_dynamo/output_graph.py:1818] [0/0] [__trace_call]     ~^^^^^^^^^
V0227 18:03:15.141000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source] TRACE starts_line /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:27 in neumann_bc (neumann_bc)
V0227 18:03:15.141000 22563112417088 torch/_dynamo/symbolic_convert.py:699] [0/0] [__trace_source]         return u
V0227 18:03:15.141000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE LOAD_FAST u []
V0227 18:03:15.141000 22563112417088 torch/_dynamo/symbolic_convert.py:725] [0/0] TRACE RETURN_VALUE None [LazyVariableTracker()]
I0227 18:03:15.142000 22563112417088 torch/_dynamo/logging.py:55] [0/0] Step 1: torchdynamo done tracing neumann_bc (RETURN_VALUE)
V0227 18:03:15.142000 22563112417088 torch/_dynamo/symbolic_convert.py:2267] [0/0] RETURN_VALUE triggered compile
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:871] [0/0] COMPILING GRAPH due to GraphCompileReason(reason='return_value', user_stack=[<FrameSummary file /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py, line 27 in neumann_bc>], graph_break=False)
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code] TRACED GRAPH
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]  ===== __compiled_fn_1 =====
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]  /cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]     def forward(self, s0 : torch.SymInt, s1 : torch.SymInt, L_u_ : torch.Tensor):
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_ = L_u_
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc, code: assert len(u.shape) == 2
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         size = l_u_.size()
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc, code: u[0, 1:ny-1]    = u[1, 1:ny-1]
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         getitem_2 = l_u_[(1, slice(1, 299, None))]
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_[(0, slice(1, 299, None))] = getitem_2;  setitem = l_u_;  getitem_2 = None
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc, code: u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         getitem_3 = l_u_[(298, slice(1, 299, None))]
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_[(299, slice(1, 299, None))] = getitem_3;  setitem_1 = l_u_;  getitem_3 = None
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:25 in neumann_bc, code: u[:, 0]    = u[:, 1]
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         getitem_4 = l_u_[(slice(None, None, None), 1)]
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_[(slice(None, None, None), 0)] = getitem_4;  setitem_2 = l_u_;  getitem_4 = None
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         # File: /cluster/home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:26 in neumann_bc, code: u[:, ny-1] = u[:, ny-2]
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         getitem_5 = l_u_[(slice(None, None, None), 298)]
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         l_u_[(slice(None, None, None), 299)] = getitem_5;  setitem_3 = l_u_;  getitem_5 = None
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         return (l_u_,)
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code]         
V0227 18:03:15.142000 22563112417088 torch/_dynamo/output_graph.py:1157] [0/0] [__graph_code] 
V0227 18:03:15.144000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] TRACED GRAPH
V0227 18:03:15.144000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph]  __compiled_fn_1 /cluster/software/stacks/2024-06/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/gcc-12.2.0/python-3.11.6-ukhwpjnwzzzizek3pgr75zkbhxros5fq/lib/python3.11/site-packages/torch/fx/_lazy_graph_module.py opcode         name       target                       args                                               kwargs
V0227 18:03:15.144000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] -------------  ---------  ---------------------------  -------------------------------------------------  --------
V0227 18:03:15.144000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] placeholder    s0         s0                           ()                                                 {}
V0227 18:03:15.144000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] placeholder    s1         s1                           ()                                                 {}
V0227 18:03:15.144000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] placeholder    l_u_       L_u_                         ()                                                 {}
V0227 18:03:15.144000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_method    size       size                         (l_u_,)                                            {}
V0227 18:03:15.144000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  getitem_2  <built-in function getitem>  (l_u_, (1, slice(1, 299, None)))                   {}
V0227 18:03:15.144000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  setitem    <built-in function setitem>  (l_u_, (0, slice(1, 299, None)), getitem_2)        {}
V0227 18:03:15.144000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  getitem_3  <built-in function getitem>  (l_u_, (298, slice(1, 299, None)))                 {}
V0227 18:03:15.144000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  setitem_1  <built-in function setitem>  (l_u_, (299, slice(1, 299, None)), getitem_3)      {}
V0227 18:03:15.144000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  getitem_4  <built-in function getitem>  (l_u_, (slice(None, None, None), 1))               {}
V0227 18:03:15.144000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  setitem_2  <built-in function setitem>  (l_u_, (slice(None, None, None), 0), getitem_4)    {}
V0227 18:03:15.144000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  getitem_5  <built-in function getitem>  (l_u_, (slice(None, None, None), 298))             {}
V0227 18:03:15.144000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] call_function  setitem_3  <built-in function setitem>  (l_u_, (slice(None, None, None), 299), getitem_5)  {}
V0227 18:03:15.144000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] output         output     output                       ((l_u_,),)                                         {}
V0227 18:03:15.144000 22563112417088 torch/_dynamo/output_graph.py:1163] [0/0] [__graph] 
V0227 18:03:15.147000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] TRACED GRAPH TENSOR SIZES
V0227 18:03:15.147000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] ===== __compiled_fn_1 =====
V0227 18:03:15.147000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] l_u_: (s0, s1)
V0227 18:03:15.147000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] l_u_ (concrete): (300, 300)
V0227 18:03:15.147000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_2: (298,)
V0227 18:03:15.147000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_3: (298,)
V0227 18:03:15.147000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_4: (s0,)
V0227 18:03:15.147000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_4 (concrete): (300,)
V0227 18:03:15.147000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_5: (s0,)
V0227 18:03:15.147000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] getitem_5 (concrete): (300,)
V0227 18:03:15.147000 22563112417088 torch/_dynamo/output_graph.py:1164] [0/0] [__graph_sizes] 
I0227 18:03:15.148000 22563112417088 torch/_dynamo/logging.py:55] [0/0] Step 2: calling compiler function dynamo_graph_accumulating_compiler
I0227 18:03:15.148000 22563112417088 torch/_dynamo/logging.py:55] [0/0] Step 2: done compiler function dynamo_graph_accumulating_compiler
I0227 18:03:15.159000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2806] [0/0] produce_guards
V0227 18:03:15.160000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].size()[0] s0 None
V0227 18:03:15.160000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].size()[1] s1 None
V0227 18:03:15.160000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].stride()[0] s1 None
V0227 18:03:15.160000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].stride()[1] 1 None
V0227 18:03:15.160000 22563112417088 torch/fx/experimental/symbolic_shapes.py:2988] [0/0] track_symint L['u'].storage_offset() 0 None
V0227 18:03:15.161000 22563112417088 torch/fx/experimental/symbolic_shapes.py:3138] [0/0] Skipping guard L['u'].stride()[1] == 1
V0227 18:03:15.161000 22563112417088 torch/fx/experimental/symbolic_shapes.py:3138] [0/0] Skipping guard L['u'].storage_offset() == 0
V0227 18:03:15.165000 22563112417088 torch/_dynamo/guards.py:1076] [0/0] [__guards] GUARDS:
V0227 18:03:15.165000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] ___check_type_id(L['u'], 86261344)                            # assert len(u.shape) == 2  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc
V0227 18:03:15.166000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] hasattr(L['u'], '_dynamo_dynamic_indices') == False           # assert len(u.shape) == 2  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc
V0227 18:03:15.166000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] ___check_type_id(L['nx'], 22563121958112)                     # u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc
V0227 18:03:15.167000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['nx'] == 300                                                # u[nx-1, 1:ny-1] = u[nx-2, 1:ny-1]  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:22 in neumann_bc
V0227 18:03:15.167000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] ___check_type_id(L['ny'], 22563121958112)                     # u[0, 1:ny-1]    = u[1, 1:ny-1]  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc
V0227 18:03:15.167000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['ny'] == 300                                                # u[0, 1:ny-1]    = u[1, 1:ny-1]  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:21 in neumann_bc
V0227 18:03:15.168000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:430 in init_ambient_guards
V0227 18:03:15.168000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] ___check_current_backend(22560122643744)                      # _dynamo/output_graph.py:436 in init_ambient_guards
V0227 18:03:15.168000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] check_tensor(L['u'], Tensor, DispatchKeySet(CUDA, BackendSelect, ADInplaceOrView, AutogradCUDA), torch.float64, device=0, requires_grad=False, size=[None, None], stride=[None, 1])  # assert len(u.shape) == 2  # home/konradha/nonlinear-solvers/nlsolvers/device/include/bc_update_kernel_fusion.py:19 in neumann_bc
V0227 18:03:15.169000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] L['u'].stride()[0] == L['u'].size()[1]                        # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.169000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] 299 <= L['u'].size()[0]                                       # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.169000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] 299 <= L['u'].size()[1]                                       # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.170000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] 299 <= L['u'].size()[0]                                       # _dynamo/output_graph.py:422 in init_ambient_guards
V0227 18:03:15.170000 22563112417088 torch/_dynamo/guards.py:1085] [0/0] [__guards] 299 <= L['u'].size()[1]                                       # _dynamo/output_graph.py:422 in init_ambient_guards
I0227 18:03:15.366000 22563112417088 torch/_dynamo/utils.py:320] TorchDynamo compilation metrics:
I0227 18:03:15.366000 22563112417088 torch/_dynamo/utils.py:320] Function    Runtimes (s)
I0227 18:03:15.366000 22563112417088 torch/_dynamo/utils.py:320] ----------  --------------
slurmstepd: error: *** JOB 24755961 ON eu-lo-g3-043 CANCELLED AT 2025-02-27T18:03:57 DUE TO TIME LIMIT ***
